{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["**Run DeViSE on ImNet-A with Basic KG**\n","---\n","You can run other settings by changing the parameters of \"dataset\" and \"semantic type\""],"metadata":{"id":"Q7V24u151wpV"}},{"cell_type":"markdown","source":["**1. Bind your Google Drive**"],"metadata":{"id":"CXw5rNMGd0ro"}},{"cell_type":"code","execution_count":16,"metadata":{"id":"XqEhfA8insO8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666188805692,"user_tz":-480,"elapsed":4446,"user":{"displayName":"黄雨峰","userId":"10355830370640481145"}},"outputId":"55499b35-7fa2-4223-c3a9-7b89a9867e66"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"markdown","source":["**2. Import Package**"],"metadata":{"id":"ytzRTj1Rd5G_"}},{"cell_type":"code","source":["import numpy as np\n","import random\n","import argparse\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader, Dataset\n","import heapq\n","import os\n","import scipy.io as scio\n","from collections import defaultdict"],"metadata":{"id":"6n7L_esb4S_z","executionInfo":{"status":"ok","timestamp":1666188809172,"user_tz":-480,"elapsed":531,"user":{"displayName":"黄雨峰","userId":"10355830370640481145"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["**3. Parameters Setting**"],"metadata":{"id":"w7DxnREleIhG"}},{"cell_type":"code","source":["parser = argparse.ArgumentParser()\n","parser.add_argument('--data_dir', default='/content/drive/MyDrive/ISWC_demo/ZS_IMGC/data', help='root directory')\n","parser.add_argument('--dataset', default='ImNet_A', help='target datasets, options: {AwA2, ImNet_A, ImNet_O}')\n","parser.add_argument('--semantic_type', default='hie', type=str, help='the type of class embedding to input, options: {att, w2v, w2v-glove, hie, kge (Basic KG), kge_text (Basic KG+literal), kge_facts (Basic KG+CN), kge_logics (Basic KG+logics)}')\n","parser.add_argument(\"--gpu\", type=int, default=0, help=\"Which GPU to use?\")\n","'''\n","Training Parameter\n","'''\n","parser.add_argument('--loss_fn', default='mse', help='loss function, options: {mse, margin}')\n","parser.add_argument('--p', default=0.5, help='dropout', type=float)\n","parser.add_argument('--batch_size', default=64, help='training batch size', type=int)\n","parser.add_argument('--lr', default=1e-3, help='learning rate', type=float)\n","parser.add_argument('--wds', default=1e-5, help='', type=float)\n","parser.add_argument('--epoch_num', default=60, help='training epoch', type=int)\n","parser.add_argument('--manual_seed', default=12345, help='random seed', type=int)\n","\n","args = parser.parse_known_args()[0]\n","\n","if args.manual_seed is None:\n","  args.manual_seed = random.randint(1, 10000)\n","print(\"Random Seed: \", args.manual_seed)\n","\n","np.random.seed(args.manual_seed)\n","random.seed(args.manual_seed)\n","torch.manual_seed(args.manual_seed)\n","if torch.cuda.is_available():\n","    torch.cuda.set_device(args.gpu)\n","    print('using gpu {}'.format(args.gpu))\n","    torch.cuda.manual_seed_all(args.manual_seed)\n","    torch.backends.cudnn.deterministic = True\n","else:\n","    print(\"GPU is not available!\")"],"metadata":{"id":"HWTtRJJA2LmO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666188815332,"user_tz":-480,"elapsed":529,"user":{"displayName":"黄雨峰","userId":"10355830370640481145"}},"outputId":"61e64ae6-1e75-4993-e5eb-04c862c884a8"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Random Seed:  12345\n","using gpu 0\n"]}]},{"cell_type":"markdown","source":["**4.  Loading Data**"],"metadata":{"id":"P2UfZwlufMnc"}},{"cell_type":"code","source":["def load_semantic_embed(data_path, dataset, type):\n","    \"\"\"\n","    Load Semantic Embeddings.\n","\n","    Parameters\n","    ----------\n","    file_name : str\n","        Name of the semantic embedding file.\n","    type: str\n","        Type of semantic embeddings, including\n","\n","    Returns\n","    -------\n","    embeddings : NumPy arrays\n","       the size is [class nums, semantic embedding dimension]\n","    Examples\n","    --------\n","    \"\"\"\n","\n","    file_name = ''\n","\n","    if dataset == 'AwA2':\n","        file_path = os.path.join(data_path, 'semantic_embeddings')\n","        if type == 'att':\n","            file_name = os.path.join(data_path, 'binaryAtt_splits.mat')\n","        elif type == 'w2v':\n","            file_name = os.path.join(file_path, 'awa_w2v.mat')\n","        elif type == 'w2v-glove':\n","            file_name = os.path.join(file_path, 'awa_w2v_glove.mat')\n","        elif type == 'hie':\n","            file_name = os.path.join(file_path, 'awa_hierarchy_gae.mat')\n","        elif type == 'kge':\n","            file_name = os.path.join(file_path, 'kge_CH_AH_CA_60000.mat')\n","        elif type == 'kge_text':\n","            file_name = os.path.join(file_path, 'kge_CH_AH_CA_60000_text_140.mat')\n","        elif type == 'kge_facts':\n","            file_name = os.path.join(file_path, 'kge_CH_AH_CA_Facts_60000_80000.mat')\n","        elif type == 'kge_logics':\n","            file_name = os.path.join(file_path, 'kge_CH_AH_CA_Logics_70000.mat')\n","        else:\n","            print(\"WARNING: invalid semantic embeddings type\")\n","\n","    else:\n","        file_path = os.path.join(data_path, dataset, 'semantic_embeddings')\n","        if type == 'hie':\n","            file_name = os.path.join(file_path, 'hierarchy_gae.mat')\n","        elif type == 'w2v':\n","            file_name = os.path.join(data_path, 'w2v.mat')\n","        elif type == 'w2v-glove':\n","            file_name = os.path.join(file_path, 'w2v_glove.mat')\n","        elif type == 'att':\n","            file_name = os.path.join(file_path, 'atts_binary.mat')\n","        # else:\n","        #     print('WARNING: invalid semantic embeddings type')\n","\n","        if dataset == 'ImNet_A':\n","            if type == 'kge':\n","                file_name = os.path.join(file_path, 'kge_CH_AH_CA_60000.mat')\n","            elif type == 'kge_text':\n","                file_name = os.path.join(file_path, 'kge_CH_AH_CA_60000_text_nei_140.mat')\n","            elif type == 'kge_facts':\n","                file_name = os.path.join(file_path, 'kge_CH_AH_CA_Facts_60000_70000.mat')\n","        if dataset == 'ImNet_O':\n","            if type == 'kge':\n","                file_name = os.path.join(file_path, 'kge_CH_AH_CA_60000.mat')\n","            elif type == 'kge_text':\n","                file_name = os.path.join(file_path, 'kge_CH_AH_CA_60000_text_nei_140.mat')\n","            elif type == 'kge_facts':\n","                file_name = os.path.join(file_path, 'kge_CH_AH_CA_Facts_60000_70000.mat')\n","    if file_name:\n","        matcontent = scio.loadmat(file_name)\n","        if dataset == 'AwA2':\n","            if type == 'att':\n","                cls_embeddings = matcontent['att'].T\n","            else:\n","                cls_embeddings = matcontent['embeddings']\n","        else:\n","            if type == 'w2v':\n","                cls_embeddings = matcontent['w2v'][:2549]\n","            else:\n","                cls_embeddings = matcontent['embeddings']\n","    else:\n","        print('WARNING: invalid semantic embeddings file path')\n","    return cls_embeddings\n","\n","\n","class DATAReader(Dataset):\n","    \"\"\"\n","    Load ZSL Data.\n","    \"\"\"\n","\n","    def __init__(self, args, type):\n","        if args.dataset == 'AwA2':\n","            data_path = os.path.join(args.data_dir, args.dataset)\n","            self.semantic_embed = load_semantic_embed(data_path, args.dataset, type=args.semantic_type)\n","            self.read_dataset(args, type)\n","        else:\n","            data_path = os.path.join(args.data_dir, 'ImageNet')\n","            self.semantic_embed = load_semantic_embed(data_path, args.dataset, type=args.semantic_type)\n","            self.read_imagenet(args, type)\n","\n","    def read_imagenet(self, args, type):\n","        data_path = os.path.join(args.data_dir, 'ImageNet')\n","\n","        def load_classes(file_name):\n","            classes = list()\n","            wnids = open(file_name, 'rU')\n","            try:\n","                for line in wnids:\n","                    classes.append(line[:-1])\n","            finally:\n","                wnids.close()\n","            return classes\n","\n","        seen_classes = load_classes(os.path.join(data_path, args.dataset, 'seen.txt'))\n","        unseen_classes = load_classes(os.path.join(data_path, args.dataset, 'unseen.txt'))\n","\n","\n","        matcontent = scio.loadmat(os.path.join(data_path, 'split.mat'))\n","        wnids = matcontent['allwnids'].squeeze().tolist()\n","\n","        if type == 'train_seen':\n","            feat_path = os.path.join(data_path, 'Res101_Features', 'ILSVRC2012_train')\n","            classes = seen_classes\n","        if type == 'test_seen':\n","            feat_path = os.path.join(data_path, 'Res101_Features', 'ILSVRC2012_val')\n","            classes = seen_classes\n","        if type == 'test_unseen':\n","            feat_path = os.path.join(data_path, 'Res101_Features', 'ILSVRC2011')\n","            classes = unseen_classes\n","\n","        # load data\n","        self.x = []\n","        self.y_tag = []  # tag\n","        self.y_vec = []  # vec\n","        self.y_vec_neg = []  # vec\n","\n","        self.all_sem_vec = []\n","        self.ids = []\n","        for cls in classes:\n","            idx = wnids.index(cls) + 1\n","\n","            feat_file = os.path.join(feat_path, str(idx) + '.mat')\n","            features = np.array(scio.loadmat(feat_file)['features'])\n","\n","            self.ids.append(idx)\n","            self.all_sem_vec.append(self.semantic_embed[idx - 1])\n","\n","\n","            for _ in range(features.shape[0]):\n","                self.y_tag.append(idx)\n","\n","            for _ in range(features.shape[0]):\n","                self.y_vec.append(self.semantic_embed[idx - 1])\n","                while True:\n","                    neg_cls = random.choice(classes)\n","                    if neg_cls != cls:\n","                        break\n","                neg_idx = wnids.index(neg_cls)\n","                self.y_vec_neg.append(self.semantic_embed[neg_idx])\n","\n","            if len(self.x) == 0:\n","                self.x = features\n","            else:\n","                self.x = np.concatenate((self.x, features), axis=0)\n","\n","        self.x = self.x.astype(np.float32)\n","        self.y_vec = np.array(self.y_vec).astype(np.float32)\n","        self.y_vec_neg = np.array(self.y_vec_neg).astype(np.float32)\n","        print(\"features data size: \", self.x.shape)  # (24700, 2048)  2450\n","        print(\"tag data len: \", len(self.y_tag))  # (24700)  2450\n","        print(\"vec data size: \", self.y_vec.shape)  # (24700,500)  2450\n","\n","        self.all_sem_vec = np.array(self.all_sem_vec)\n","        # print(self.y_tag)\n","\n","\n","\n","\n","    def read_dataset(self, args, type):\n","\n","        data_path = os.path.join(args.data_dir, args.dataset)\n","        # load cnn features\n","        matcontent = scio.loadmat(os.path.join(data_path, 'res101.mat'))\n","        features = matcontent['features'].T\n","        labels = matcontent['labels'].astype(int).squeeze() - 1\n","\n","        split_matcontent = scio.loadmat(os.path.join(data_path, 'binaryAtt_splits.mat'))\n","\n","        if type == 'train_seen':\n","            loc = split_matcontent['trainval_loc'].squeeze() - 1\n","        if type == 'test_seen':\n","            loc = split_matcontent['test_seen_loc'].squeeze() - 1\n","        if type == 'test_unseen':\n","            loc = split_matcontent['test_unseen_loc'].squeeze() - 1\n","\n","\n","\n","        self.x = features[loc]\n","        self.y_tag = labels[loc]\n","        all_tags = np.unique(self.y_tag)\n","\n","        self.y_vec = []\n","        self.y_vec_neg = []\n","        for i in range(self.y_tag.shape[0]):\n","            self.y_vec.append(self.semantic_embed[self.y_tag[i]])\n","            while True:\n","                neg_tag = random.choice(all_tags)\n","                if neg_tag != self.y_tag[i]:\n","                    break\n","            self.y_vec_neg.append(self.semantic_embed[neg_tag])\n","\n","\n","        self.x = self.x.astype(np.float32)\n","        self.y_vec = np.array(self.y_vec).astype(np.float32)\n","        self.y_vec_neg = np.array(self.y_vec_neg).astype(np.float32)\n","\n","        print(\"features data size: \", self.x.shape)  # (24700, 2048)  2450\n","        print(\"semantic data size: \", self.y_vec.shape)  # (24700,500)  2450\n","\n","\n","        self.ids = all_tags.tolist()\n","\n","\n","        self.all_sem_vec = []\n","        for i in range(all_tags.shape[0]):\n","            self.all_sem_vec.append(self.semantic_embed[all_tags[i]])\n","        self.all_sem_vec = np.array(self.all_sem_vec)\n","\n","\n","    def __len__(self):\n","        return (self.x.shape[0])\n","\n","    def __getitem__(self, idx):\n","        tmp_x = self.x[idx]\n","        tmp_y_tag = self.y_tag[idx]\n","        tmp_y_vec = self.y_vec[idx]\n","        tmp_y_vec_neg = self.y_vec_neg[idx]\n","\n","        return (tmp_x, (tmp_y_vec, tmp_y_vec_neg, tmp_y_tag)) #vec  tag"],"metadata":{"id":"MBH57F2f6_6Y","executionInfo":{"status":"ok","timestamp":1666188821526,"user_tz":-480,"elapsed":534,"user":{"displayName":"黄雨峰","userId":"10355830370640481145"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":["**5. DeViSE model**"],"metadata":{"id":"hnrswfGXftxI"}},{"cell_type":"code","source":["class devise(nn.Module):\n","    def __init__(self, input_dims, output_dims, p):\n","        super(devise, self).__init__()\n","        self.model = nn.Sequential(nn.BatchNorm1d(input_dims),\n","                         nn.Dropout(p),\n","                         nn.Linear(in_features=input_dims, out_features=2048, bias=True),\n","                         nn.ReLU(),\n","                         nn.BatchNorm1d(2048),\n","                         nn.Dropout(p),\n","                         nn.Linear(in_features=2048, out_features=output_dims, bias=True))\n","    def forward(self, x):\n","        x = self.model(x)\n","        return x"],"metadata":{"id":"c9Owz1q37UwN","executionInfo":{"status":"ok","timestamp":1666188836970,"user_tz":-480,"elapsed":2,"user":{"displayName":"黄雨峰","userId":"10355830370640481145"}}},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":["**6. Evaluation Functions**"],"metadata":{"id":"ANwjZqm6fzRm"}},{"cell_type":"code","source":["def macro_acc(true_label, pre_label):\n","    \"\"\"\n","    Evaluation Metrics: Macro Accuracy, compute accuracy for each class and average accuracies over all testing classes\n","    \"\"\"\n","    label_2_num = defaultdict(int)\n","    label_pre_true_num = defaultdict(int)\n","    label_2_acc = defaultdict(float)\n","\n","    sz = len(true_label)\n","    for i in range(sz):\n","        label_2_num[true_label[i]] += 1\n","        if (pre_label[i] == true_label[i]):\n","            label_pre_true_num[true_label[i]] += 1\n","    for label, num in label_2_num.items():\n","        label_2_acc[label] = float(label_pre_true_num[label] / num)\n","    sum = 0.\n","    for i, j in label_2_acc.items():\n","        sum += j\n","\n","    return sum / len(label_2_acc)\n","\n","\n","def dtest(te, model, id_space, sem_space, loss_fn):\n","\n","    sem_space = sem_space.transpose()\n","\n","    with torch.no_grad():\n","        model.eval()\n","        real_label_test = []\n","        pre_label_test_1 = []\n","        pre_label_test_2 = []  # hit 2\n","        pre_label_test_5 = []  # hit 5\n","        loss_total_test = 0\n","        for (vx, vy) in te:\n","            val_vec_y, val_vec_y_neg, val_tag_y = vy\n","            val_vec_y = val_vec_y.cuda()\n","            val_vec_y_neg = val_vec_y_neg.cuda()\n","            vx = vx.cuda()\n","\n","            vy_pred = model(vx)\n","\n","\n","            if loss_fn == 'mse':\n","                loss_fn = nn.MSELoss()\n","                vloss = loss_fn(vy_pred, val_vec_y)\n","\n","            if loss_fn == 'margin':\n","                pos_score = F.cosine_similarity(vy_pred, val_vec_y)\n","                neg_score = F.cosine_similarity(vy_pred, val_vec_y_neg)\n","                vloss = torch.mean(torch.max(1.0 - pos_score + neg_score,\n","                                            torch.zeros_like(pos_score).cuda()))\n","\n","\n","            loss_total_test += vloss.item()\n","            val_tag_y = [t.item() for t in val_tag_y]\n","            real_label_test.extend(val_tag_y)\n","            vy_pred_cpu = vy_pred.cpu().detach().numpy()\n","            vsz = len(val_tag_y)\n","            vtt = np.dot(vy_pred_cpu, sem_space)  # judge by dot Multiplication\n","            for n in range(vsz):\n","                e = heapq.nlargest(5, range(len(vtt[n])), vtt[n].take)  # top 5 hit\n","                vi = 0\n","                while vi < 5:\n","                    if (id_space[e[vi]] == val_tag_y[n]):  # pre right\n","                        break\n","                    vi += 1\n","                pre_label_test_1.append(id_space[e[0]])\n","                pre_label_test_2.append(id_space[e[0]])\n","                pre_label_test_5.append(id_space[e[0]])\n","\n","                if (vi <= 1):\n","                    pre_label_test_2[-1] = val_tag_y[n]\n","                    pre_label_test_5[-1] = val_tag_y[n]\n","                elif (vi <= 4):\n","                    pre_label_test_5[-1] = val_tag_y[n]\n","\n","        acc_test_1 = macro_acc(real_label_test, pre_label_test_1)\n","        acc_test_2 = macro_acc(real_label_test, pre_label_test_2)\n","        acc_test_5 = macro_acc(real_label_test, pre_label_test_5)\n","\n","        return acc_test_1, acc_test_2, acc_test_5, loss_total_test"],"metadata":{"id":"9dVpmIzD7mIS","executionInfo":{"status":"ok","timestamp":1666188840642,"user_tz":-480,"elapsed":4,"user":{"displayName":"黄雨峰","userId":"10355830370640481145"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["**7. Model Training**"],"metadata":{"id":"gOakQnt3gMda"}},{"cell_type":"code","source":["def train():\n","    # load training data (seen classes)\n","    tr_img = DATAReader(args, 'train_seen')\n","    tr = DataLoader(tr_img, batch_size=args.batch_size, shuffle=True, num_workers=8)\n","\n","    model = devise(tr_img.x.shape[1], tr_img.y_vec.shape[1], args.p).cuda()\n","\n","\n","    optimizer_tag = optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.wds)\n","    print('using {} as criterion'.format(args.loss_fn))\n","\n","    # load unseen testing data\n","    te_img_unseen = DATAReader(args, 'test_unseen')\n","    te_unseen = DataLoader(te_img_unseen, batch_size=50, num_workers=8)\n","\n","    # # load seen testing data\n","    te_img_seen = DATAReader(args, 'test_seen')\n","    te_seen = DataLoader(te_img_seen, batch_size=50, num_workers=8)\n","\n","\n","    print('Begin Training ...')\n","\n","    for epoch in range(args.epoch_num):\n","        model.train()\n","        loss_total = 0\n","\n","        real_label = []\n","        pre_label_1 = []\n","        for i, (x, y) in enumerate(tr, 1):\n","            vec_y, vec_y_neg, tag_y = y  # vec  tag\n","            x = x.cuda()\n","            vec_y = vec_y.cuda()\n","            vec_y_neg = vec_y_neg.cuda()\n","            model.zero_grad()\n","            y_pred = model(x)\n","\n","            if args.loss_fn == 'mse':\n","                loss_fn = nn.MSELoss()\n","                loss = loss_fn(y_pred, vec_y)\n","\n","            if args.loss_fn == 'margin':\n","                pos_score = F.cosine_similarity(y_pred, vec_y)\n","                neg_score = F.cosine_similarity(y_pred, vec_y_neg)\n","\n","                loss = torch.mean(torch.max(1.0 - pos_score + neg_score,\n","                                                torch.zeros_like(pos_score).cuda()))\n","\n","\n","            loss.backward()\n","            optimizer_tag.step()\n","            tag_y = [t.item() for t in tag_y]\n","            real_label.extend(tag_y)  # batch_size\n","            sz = len(tag_y)\n","            y_pred_cpu = y_pred.cpu().detach().numpy()\n","            tt = np.dot(y_pred_cpu, tr_img.all_sem_vec.transpose())  # judge by dot Multiplication\n","            for n in range(sz):\n","                e = heapq.nlargest(5, range(len(tt[n])), tt[n].take)\n","                ii = 0\n","                while ii < 5:\n","                    if(tr_img.ids[e[ii]] == tag_y[n]):\n","                        break\n","                    ii += 1\n","                pre_label_1.append(tr_img.ids[e[0]])\n","\n","\n","\n","            loss_total += loss.item()\n","\n","        acc_1 = macro_acc(real_label, pre_label_1)  # hit 1\n","        print()\n","        print('Epoch {:2d}/{:2d}; ----- total_loss:{:06.5f}; macro_acc_1: {:04.2f} -----'.format(epoch, args.epoch_num, loss_total,acc_1*100))\n","\n","        # gzsl: testing unseen\n","        acc_test_1, acc_test_2, acc_test_5, loss_total_test = \\\n","            dtest(te_unseen, model, te_img_unseen.ids, te_img_unseen.all_sem_vec, args.loss_fn)\n","\n","        print('Test Standard ZSL  | Hit 1: {:04.2f}%; Hit 2: {:04.2f}%; Hit 5: {:04.2f}%'.format(acc_test_1 * 100, acc_test_2 * 100, acc_test_5 * 100))\n","\n","\n","        # gzsl: testing unseen + seen\n","        acc_unseen, _, _, loss_total_test = \\\n","            dtest(te_unseen, model, te_img_unseen.ids + te_img_seen.ids,\n","                  np.vstack((te_img_unseen.all_sem_vec, te_img_seen.all_sem_vec)), args.loss_fn)\n","\n","        acc_seen, _, _, loss_total_test = \\\n","            dtest(te_seen, model, te_img_unseen.ids + te_img_seen.ids,\n","                  np.vstack((te_img_unseen.all_sem_vec, te_img_seen.all_sem_vec)), args.loss_fn)\n","\n","        mean = 2 * acc_seen * acc_unseen / (acc_seen + acc_unseen)\n","        print('Test Generalized ZSL | Acc Seen: {:04.2f}%; Acc Unseen: {:04.2f}%; Mean: {:04.2f}%'.format(acc_seen * 100,\n","                                                                                                 acc_unseen * 100,\n","                                                                                              mean * 100))\n","        "],"metadata":{"id":"BYYTDK4K711I","executionInfo":{"status":"ok","timestamp":1666188850780,"user_tz":-480,"elapsed":538,"user":{"displayName":"黄雨峰","userId":"10355830370640481145"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hEmkY6yn84Ho","executionInfo":{"status":"ok","timestamp":1665411445554,"user_tz":-480,"elapsed":1457536,"user":{"displayName":"黄雨峰","userId":"10355830370640481145"}},"outputId":"3de33319-9747-4915-e756-51e52c73ca8a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: DeprecationWarning: 'U' mode is deprecated\n"]},{"output_type":"stream","name":"stdout","text":["features data size:  (35150, 2048)\n","tag data len:  35150\n","vec data size:  (35150, 100)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["using mse as criterion\n","features data size:  (39523, 2048)\n","tag data len:  39523\n","vec data size:  (39523, 100)\n","features data size:  (1400, 2048)\n","tag data len:  1400\n","vec data size:  (1400, 100)\n","Begin Training ...\n","Epoch  0/60; ----- total_loss:38.96863; macro_acc_1: 65.08 -----\n","Test ZSL  | Hit 1: 29.74%; Hit 2: 59.50%; Hit 5: 94.11%\n","Test GZSL | Acc Seen: 63.29%; Acc Unseen: 1.67%; Mean: 3.25%\n","\n","Epoch  1/60; ----- total_loss:10.64372; macro_acc_1: 67.14 -----\n","Test ZSL  | Hit 1: 30.49%; Hit 2: 59.30%; Hit 5: 93.73%\n","Test GZSL | Acc Seen: 59.36%; Acc Unseen: 0.64%; Mean: 1.27%\n","\n","Epoch  2/60; ----- total_loss:9.32034; macro_acc_1: 68.09 -----\n","Test ZSL  | Hit 1: 29.98%; Hit 2: 59.53%; Hit 5: 94.31%\n","Test GZSL | Acc Seen: 63.93%; Acc Unseen: 1.10%; Mean: 2.17%\n","\n","Epoch  3/60; ----- total_loss:7.30298; macro_acc_1: 68.96 -----\n","Test ZSL  | Hit 1: 30.45%; Hit 2: 60.65%; Hit 5: 94.08%\n","Test GZSL | Acc Seen: 62.79%; Acc Unseen: 1.61%; Mean: 3.15%\n","\n","Epoch  4/60; ----- total_loss:5.79971; macro_acc_1: 69.22 -----\n","Test ZSL  | Hit 1: 30.67%; Hit 2: 58.66%; Hit 5: 93.86%\n","Test GZSL | Acc Seen: 63.50%; Acc Unseen: 1.65%; Mean: 3.21%\n","\n","Epoch  5/60; ----- total_loss:4.85923; macro_acc_1: 70.01 -----\n","Test ZSL  | Hit 1: 30.46%; Hit 2: 59.04%; Hit 5: 93.73%\n","Test GZSL | Acc Seen: 63.57%; Acc Unseen: 1.17%; Mean: 2.30%\n","\n","Epoch  6/60; ----- total_loss:4.24682; macro_acc_1: 69.98 -----\n","Test ZSL  | Hit 1: 30.41%; Hit 2: 58.08%; Hit 5: 94.05%\n","Test GZSL | Acc Seen: 62.36%; Acc Unseen: 1.49%; Mean: 2.91%\n","\n","Epoch  7/60; ----- total_loss:3.92715; macro_acc_1: 69.95 -----\n","Test ZSL  | Hit 1: 30.50%; Hit 2: 58.91%; Hit 5: 93.42%\n","Test GZSL | Acc Seen: 63.86%; Acc Unseen: 1.30%; Mean: 2.55%\n","\n","Epoch  8/60; ----- total_loss:3.85116; macro_acc_1: 70.12 -----\n","Test ZSL  | Hit 1: 30.68%; Hit 2: 58.50%; Hit 5: 94.26%\n","Test GZSL | Acc Seen: 64.00%; Acc Unseen: 1.38%; Mean: 2.71%\n","\n","Epoch  9/60; ----- total_loss:3.85235; macro_acc_1: 70.09 -----\n","Test ZSL  | Hit 1: 30.60%; Hit 2: 59.09%; Hit 5: 93.91%\n","Test GZSL | Acc Seen: 62.93%; Acc Unseen: 1.47%; Mean: 2.88%\n","\n","Epoch 10/60; ----- total_loss:3.87647; macro_acc_1: 70.09 -----\n","Test ZSL  | Hit 1: 31.05%; Hit 2: 59.35%; Hit 5: 94.92%\n","Test GZSL | Acc Seen: 63.86%; Acc Unseen: 1.29%; Mean: 2.53%\n","\n","Epoch 11/60; ----- total_loss:3.89936; macro_acc_1: 69.96 -----\n","Test ZSL  | Hit 1: 30.84%; Hit 2: 59.73%; Hit 5: 94.59%\n","Test GZSL | Acc Seen: 63.14%; Acc Unseen: 1.62%; Mean: 3.17%\n","\n","Epoch 12/60; ----- total_loss:3.95798; macro_acc_1: 69.93 -----\n","Test ZSL  | Hit 1: 30.62%; Hit 2: 59.45%; Hit 5: 94.30%\n","Test GZSL | Acc Seen: 63.57%; Acc Unseen: 1.40%; Mean: 2.73%\n","\n","Epoch 13/60; ----- total_loss:4.02318; macro_acc_1: 69.74 -----\n","Test ZSL  | Hit 1: 30.65%; Hit 2: 58.64%; Hit 5: 94.19%\n","Test GZSL | Acc Seen: 63.57%; Acc Unseen: 1.47%; Mean: 2.87%\n","\n","Epoch 14/60; ----- total_loss:4.07198; macro_acc_1: 69.51 -----\n","Test ZSL  | Hit 1: 30.48%; Hit 2: 58.67%; Hit 5: 93.78%\n","Test GZSL | Acc Seen: 63.29%; Acc Unseen: 1.47%; Mean: 2.88%\n","\n","Epoch 15/60; ----- total_loss:4.08608; macro_acc_1: 69.72 -----\n","Test ZSL  | Hit 1: 30.65%; Hit 2: 59.92%; Hit 5: 94.25%\n","Test GZSL | Acc Seen: 64.14%; Acc Unseen: 1.58%; Mean: 3.08%\n","\n","Epoch 16/60; ----- total_loss:4.14090; macro_acc_1: 69.61 -----\n","Test ZSL  | Hit 1: 30.56%; Hit 2: 59.32%; Hit 5: 93.66%\n","Test GZSL | Acc Seen: 62.14%; Acc Unseen: 1.57%; Mean: 3.07%\n","\n","Epoch 17/60; ----- total_loss:4.17985; macro_acc_1: 69.59 -----\n","Test ZSL  | Hit 1: 30.33%; Hit 2: 58.83%; Hit 5: 94.07%\n","Test GZSL | Acc Seen: 62.71%; Acc Unseen: 1.29%; Mean: 2.53%\n","\n","Epoch 18/60; ----- total_loss:4.20748; macro_acc_1: 69.52 -----\n","Test ZSL  | Hit 1: 30.81%; Hit 2: 59.04%; Hit 5: 93.95%\n","Test GZSL | Acc Seen: 61.00%; Acc Unseen: 1.52%; Mean: 2.97%\n","\n","Epoch 19/60; ----- total_loss:4.23774; macro_acc_1: 69.47 -----\n","Test ZSL  | Hit 1: 30.42%; Hit 2: 59.31%; Hit 5: 93.76%\n","Test GZSL | Acc Seen: 62.64%; Acc Unseen: 1.23%; Mean: 2.41%\n","\n","Epoch 20/60; ----- total_loss:4.22738; macro_acc_1: 69.62 -----\n","Test ZSL  | Hit 1: 30.46%; Hit 2: 58.54%; Hit 5: 94.55%\n","Test GZSL | Acc Seen: 63.64%; Acc Unseen: 1.36%; Mean: 2.66%\n","\n","Epoch 21/60; ----- total_loss:4.22935; macro_acc_1: 69.56 -----\n","Test ZSL  | Hit 1: 30.69%; Hit 2: 59.05%; Hit 5: 93.93%\n","Test GZSL | Acc Seen: 62.71%; Acc Unseen: 1.51%; Mean: 2.96%\n","\n","Epoch 22/60; ----- total_loss:4.21784; macro_acc_1: 69.58 -----\n","Test ZSL  | Hit 1: 30.47%; Hit 2: 58.80%; Hit 5: 93.95%\n","Test GZSL | Acc Seen: 62.64%; Acc Unseen: 1.22%; Mean: 2.40%\n","\n","Epoch 23/60; ----- total_loss:4.23750; macro_acc_1: 69.46 -----\n","Test ZSL  | Hit 1: 30.80%; Hit 2: 59.32%; Hit 5: 94.01%\n","Test GZSL | Acc Seen: 64.14%; Acc Unseen: 1.29%; Mean: 2.54%\n","\n","Epoch 24/60; ----- total_loss:4.26212; macro_acc_1: 69.55 -----\n","Test ZSL  | Hit 1: 30.82%; Hit 2: 59.23%; Hit 5: 93.62%\n","Test GZSL | Acc Seen: 63.07%; Acc Unseen: 1.60%; Mean: 3.12%\n","\n","Epoch 25/60; ----- total_loss:4.19232; macro_acc_1: 69.62 -----\n","Test ZSL  | Hit 1: 30.41%; Hit 2: 59.68%; Hit 5: 93.84%\n","Test GZSL | Acc Seen: 62.57%; Acc Unseen: 1.10%; Mean: 2.16%\n","\n","Epoch 26/60; ----- total_loss:4.24527; macro_acc_1: 69.58 -----\n","Test ZSL  | Hit 1: 30.75%; Hit 2: 59.14%; Hit 5: 93.77%\n","Test GZSL | Acc Seen: 60.64%; Acc Unseen: 1.53%; Mean: 2.99%\n","\n","Epoch 27/60; ----- total_loss:4.23965; macro_acc_1: 69.54 -----\n","Test ZSL  | Hit 1: 30.89%; Hit 2: 59.23%; Hit 5: 94.67%\n","Test GZSL | Acc Seen: 61.93%; Acc Unseen: 1.08%; Mean: 2.12%\n","\n","Epoch 28/60; ----- total_loss:4.21957; macro_acc_1: 69.60 -----\n","Test ZSL  | Hit 1: 30.75%; Hit 2: 59.74%; Hit 5: 94.46%\n","Test GZSL | Acc Seen: 63.36%; Acc Unseen: 1.06%; Mean: 2.08%\n","\n","Epoch 29/60; ----- total_loss:4.20267; macro_acc_1: 69.46 -----\n","Test ZSL  | Hit 1: 30.63%; Hit 2: 59.28%; Hit 5: 94.30%\n","Test GZSL | Acc Seen: 64.50%; Acc Unseen: 1.36%; Mean: 2.67%\n","\n","Epoch 30/60; ----- total_loss:4.25259; macro_acc_1: 69.59 -----\n","Test ZSL  | Hit 1: 30.65%; Hit 2: 59.15%; Hit 5: 94.07%\n","Test GZSL | Acc Seen: 63.14%; Acc Unseen: 1.64%; Mean: 3.20%\n","\n","Epoch 31/60; ----- total_loss:4.22211; macro_acc_1: 69.55 -----\n","Test ZSL  | Hit 1: 30.78%; Hit 2: 59.66%; Hit 5: 93.74%\n","Test GZSL | Acc Seen: 62.71%; Acc Unseen: 1.54%; Mean: 3.00%\n","\n","Epoch 32/60; ----- total_loss:4.24488; macro_acc_1: 69.74 -----\n","Test ZSL  | Hit 1: 30.60%; Hit 2: 58.89%; Hit 5: 93.85%\n","Test GZSL | Acc Seen: 64.71%; Acc Unseen: 1.31%; Mean: 2.56%\n","\n","Epoch 33/60; ----- total_loss:4.21176; macro_acc_1: 69.67 -----\n","Test ZSL  | Hit 1: 30.97%; Hit 2: 59.88%; Hit 5: 94.79%\n","Test GZSL | Acc Seen: 64.14%; Acc Unseen: 1.21%; Mean: 2.38%\n","\n","Epoch 34/60; ----- total_loss:4.22245; macro_acc_1: 69.69 -----\n","Test ZSL  | Hit 1: 30.72%; Hit 2: 59.68%; Hit 5: 94.75%\n","Test GZSL | Acc Seen: 63.07%; Acc Unseen: 1.30%; Mean: 2.55%\n","\n","Epoch 35/60; ----- total_loss:4.24444; macro_acc_1: 69.67 -----\n","Test ZSL  | Hit 1: 31.01%; Hit 2: 59.73%; Hit 5: 94.36%\n","Test GZSL | Acc Seen: 61.21%; Acc Unseen: 1.50%; Mean: 2.94%\n","\n","Epoch 36/60; ----- total_loss:4.20430; macro_acc_1: 69.60 -----\n","Test ZSL  | Hit 1: 30.52%; Hit 2: 59.14%; Hit 5: 94.32%\n","Test GZSL | Acc Seen: 64.29%; Acc Unseen: 1.49%; Mean: 2.90%\n","\n","Epoch 37/60; ----- total_loss:4.26758; macro_acc_1: 69.48 -----\n","Test ZSL  | Hit 1: 30.86%; Hit 2: 59.53%; Hit 5: 94.51%\n","Test GZSL | Acc Seen: 64.43%; Acc Unseen: 1.37%; Mean: 2.68%\n","\n","Epoch 38/60; ----- total_loss:4.21416; macro_acc_1: 69.46 -----\n","Test ZSL  | Hit 1: 30.61%; Hit 2: 59.92%; Hit 5: 94.78%\n","Test GZSL | Acc Seen: 63.79%; Acc Unseen: 1.22%; Mean: 2.40%\n","\n","Epoch 39/60; ----- total_loss:4.21108; macro_acc_1: 69.69 -----\n","Test ZSL  | Hit 1: 30.25%; Hit 2: 59.69%; Hit 5: 93.79%\n","Test GZSL | Acc Seen: 62.93%; Acc Unseen: 1.59%; Mean: 3.09%\n","\n","Epoch 40/60; ----- total_loss:4.26617; macro_acc_1: 69.54 -----\n","Test ZSL  | Hit 1: 30.90%; Hit 2: 59.42%; Hit 5: 94.50%\n","Test GZSL | Acc Seen: 63.79%; Acc Unseen: 1.15%; Mean: 2.25%\n","\n","Epoch 41/60; ----- total_loss:4.23765; macro_acc_1: 69.60 -----\n","Test ZSL  | Hit 1: 30.44%; Hit 2: 58.94%; Hit 5: 94.62%\n","Test GZSL | Acc Seen: 62.93%; Acc Unseen: 1.44%; Mean: 2.82%\n","\n","Epoch 42/60; ----- total_loss:4.22406; macro_acc_1: 69.49 -----\n","Test ZSL  | Hit 1: 30.19%; Hit 2: 58.84%; Hit 5: 94.31%\n","Test GZSL | Acc Seen: 63.79%; Acc Unseen: 1.60%; Mean: 3.13%\n","\n","Epoch 43/60; ----- total_loss:4.24852; macro_acc_1: 69.46 -----\n","Test ZSL  | Hit 1: 30.29%; Hit 2: 59.52%; Hit 5: 94.59%\n","Test GZSL | Acc Seen: 65.21%; Acc Unseen: 1.31%; Mean: 2.57%\n","\n","Epoch 44/60; ----- total_loss:4.23930; macro_acc_1: 69.62 -----\n","Test ZSL  | Hit 1: 31.13%; Hit 2: 60.23%; Hit 5: 94.32%\n","Test GZSL | Acc Seen: 64.00%; Acc Unseen: 1.48%; Mean: 2.89%\n","\n","Epoch 45/60; ----- total_loss:4.23806; macro_acc_1: 69.66 -----\n","Test ZSL  | Hit 1: 30.66%; Hit 2: 59.26%; Hit 5: 94.54%\n","Test GZSL | Acc Seen: 64.93%; Acc Unseen: 1.28%; Mean: 2.52%\n","\n","Epoch 46/60; ----- total_loss:4.16746; macro_acc_1: 69.59 -----\n","Test ZSL  | Hit 1: 30.47%; Hit 2: 58.24%; Hit 5: 93.63%\n","Test GZSL | Acc Seen: 60.21%; Acc Unseen: 1.45%; Mean: 2.84%\n","\n","Epoch 47/60; ----- total_loss:4.25395; macro_acc_1: 69.48 -----\n","Test ZSL  | Hit 1: 30.24%; Hit 2: 58.18%; Hit 5: 93.73%\n","Test GZSL | Acc Seen: 63.79%; Acc Unseen: 1.46%; Mean: 2.85%\n","\n","Epoch 48/60; ----- total_loss:4.21380; macro_acc_1: 69.68 -----\n","Test ZSL  | Hit 1: 30.70%; Hit 2: 60.01%; Hit 5: 94.75%\n","Test GZSL | Acc Seen: 64.43%; Acc Unseen: 1.04%; Mean: 2.04%\n","\n","Epoch 49/60; ----- total_loss:4.20457; macro_acc_1: 69.67 -----\n","Test ZSL  | Hit 1: 30.77%; Hit 2: 59.13%; Hit 5: 93.64%\n","Test GZSL | Acc Seen: 62.64%; Acc Unseen: 1.45%; Mean: 2.83%\n","\n","Epoch 50/60; ----- total_loss:4.20876; macro_acc_1: 69.46 -----\n","Test ZSL  | Hit 1: 30.55%; Hit 2: 58.50%; Hit 5: 94.50%\n","Test GZSL | Acc Seen: 62.86%; Acc Unseen: 1.60%; Mean: 3.12%\n","\n","Epoch 51/60; ----- total_loss:4.22308; macro_acc_1: 69.52 -----\n","Test ZSL  | Hit 1: 30.18%; Hit 2: 58.87%; Hit 5: 93.73%\n","Test GZSL | Acc Seen: 61.64%; Acc Unseen: 1.19%; Mean: 2.34%\n","\n","Epoch 52/60; ----- total_loss:4.25346; macro_acc_1: 69.65 -----\n","Test ZSL  | Hit 1: 30.72%; Hit 2: 59.25%; Hit 5: 93.75%\n","Test GZSL | Acc Seen: 61.57%; Acc Unseen: 1.52%; Mean: 2.96%\n","\n","Epoch 53/60; ----- total_loss:4.25871; macro_acc_1: 69.69 -----\n","Test ZSL  | Hit 1: 30.57%; Hit 2: 59.17%; Hit 5: 93.63%\n","Test GZSL | Acc Seen: 64.36%; Acc Unseen: 1.28%; Mean: 2.52%\n","\n","Epoch 54/60; ----- total_loss:4.25902; macro_acc_1: 69.65 -----\n","Test ZSL  | Hit 1: 30.63%; Hit 2: 59.93%; Hit 5: 94.54%\n","Test GZSL | Acc Seen: 61.71%; Acc Unseen: 1.70%; Mean: 3.32%\n","\n","Epoch 55/60; ----- total_loss:4.20267; macro_acc_1: 69.61 -----\n","Test ZSL  | Hit 1: 30.80%; Hit 2: 59.56%; Hit 5: 94.03%\n","Test GZSL | Acc Seen: 63.21%; Acc Unseen: 1.44%; Mean: 2.82%\n","\n","Epoch 56/60; ----- total_loss:4.25738; macro_acc_1: 69.57 -----\n","Test ZSL  | Hit 1: 30.82%; Hit 2: 59.50%; Hit 5: 94.71%\n","Test GZSL | Acc Seen: 63.00%; Acc Unseen: 1.51%; Mean: 2.96%\n","\n","Epoch 57/60; ----- total_loss:4.21817; macro_acc_1: 69.53 -----\n","Test ZSL  | Hit 1: 29.88%; Hit 2: 58.11%; Hit 5: 94.36%\n","Test GZSL | Acc Seen: 64.07%; Acc Unseen: 1.24%; Mean: 2.43%\n","\n","Epoch 58/60; ----- total_loss:4.23815; macro_acc_1: 69.67 -----\n","Test ZSL  | Hit 1: 30.54%; Hit 2: 59.20%; Hit 5: 94.83%\n","Test GZSL | Acc Seen: 62.50%; Acc Unseen: 1.58%; Mean: 3.07%\n","\n","Epoch 59/60; ----- total_loss:4.24373; macro_acc_1: 69.57 -----\n","Test ZSL  | Hit 1: 30.88%; Hit 2: 59.41%; Hit 5: 94.33%\n","Test GZSL | Acc Seen: 63.57%; Acc Unseen: 1.65%; Mean: 3.21%\n","\n"]}]}]}