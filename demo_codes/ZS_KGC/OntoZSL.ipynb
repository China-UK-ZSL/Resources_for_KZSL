{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["**Run OntoZSL on NELL with RDFS**\n","---\n","\n","The parameters in other settings are attached in the end.\n"],"metadata":{"id":"kRR3r-Kgxg6s"}},{"cell_type":"markdown","source":["**1. Bind your Google Drive**"],"metadata":{"id":"lEluhxuhxn7g"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"RMFjGO1mi9vN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1666194097768,"user_tz":-480,"elapsed":4198,"user":{"displayName":"黄雨峰","userId":"10355830370640481145"}},"outputId":"195a93b2-3459-46eb-c0e3-97174ebe19a4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"markdown","source":["**2. Import Package**"],"metadata":{"id":"gFgnqABkxq6E"}},{"cell_type":"code","source":["import os\n","import sys\n","import json\n","import random\n","import shutil\n","import logging\n","import argparse\n","import numpy as np\n","import os.path as osp\n","from tqdm import tqdm\n","from collections import defaultdict\n","from collections import deque\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.init as init\n","import torch.nn.functional as F\n","from torch import optim\n","from torch.autograd import Variable\n","from torch.nn.functional import normalize\n","from torch.nn.parameter import Parameter"],"metadata":{"id":"0yBFzu2ujPdX","executionInfo":{"status":"ok","timestamp":1666194103234,"user_tz":-480,"elapsed":3272,"user":{"displayName":"黄雨峰","userId":"10355830370640481145"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["**3. Data Load and Preparation, including data for pre-training Feature Encoder, model training and semantic embedding data**"],"metadata":{"id":"v1j8SGHUyBSw"}},{"cell_type":"code","source":["def random_pick(some_list, probabilities):\n","    # print(\"random pick:\", seed)\n","    # random.seed(seed)\n","    x = random.uniform(0,1)\n","    cumulative_probability = 0.0\n","    for item, item_probability in zip(some_list, probabilities):\n","        cumulative_probability += item_probability\n","        if x < cumulative_probability:break\n","    return item\n","\n","# Using\n","def Extractor_generate(seed, dataset, train_tasks, batch_size, symbol2id, ent2id, e1rel_e2, few, sub_epoch):\n","    # print(\"extract generate:\", seed)\n","    random.seed(seed)\n","    print('\\nLOADING PRETRAIN TRAINING DATA')\n","    # train_tasks = json.load(open(dataset + '/train_tasks.json'))\n","    rel2candidates = json.load(open(dataset + '/rel2candidates_all.json'))\n","\n","    task_pool = train_tasks.keys()\n","\n","    t_num = list()\n","    for k in task_pool:\n","        v = min(len(rel2candidates[k]), 1000)\n","        t_num.append(v)\n","    t_sum = sum(t_num)\n","    probability = [float(item)/t_sum for item in t_num]\n","\n","    while True:\n","        support_pairs, query_pairs, false_pairs, support_left, support_right, query_left, query_right, false_left, false_right = \\\n","           list(), list(), list(), list(), list(), list(), list(), list(), list()\n","        # query = random_pick(seed, task_pool, probability)\n","\n","        query = random_pick(task_pool, probability)\n","        candidates = rel2candidates[query]\n","        if len(candidates) <= 20:\n","            continue\n","\n","\n","        for _ in range(sub_epoch):\n","            candidates = rel2candidates[query]\n","\n","            if len(candidates) <= 20:\n","                continue\n","\n","            train_and_test = train_tasks[query]\n","\n","            random.shuffle(train_and_test)\n","\n","            support_triples = train_and_test[:few]\n","\n","            support_pairs += [[symbol2id[triple[0]], symbol2id[triple[2]]] for triple in support_triples]\n","\n","            support_left += [ent2id[triple[0]] for triple in support_triples]\n","            support_right += [ent2id[triple[2]] for triple in support_triples]\n","\n","            all_test_triples = train_and_test[few:]\n","\n","            if len(all_test_triples) == 0:\n","                continue\n","\n","            if len(all_test_triples) < batch_size:\n","                query_triples = [random.choice(all_test_triples) for _ in range(batch_size)]\n","            else:\n","                query_triples = random.sample(all_test_triples, batch_size)\n","\n","            query_pairs += [[symbol2id[triple[0]], symbol2id[triple[2]]] for triple in query_triples]\n","\n","            query_left += [ent2id[triple[0]] for triple in query_triples]\n","            query_right += [ent2id[triple[2]] for triple in query_triples]\n","\n","            for triple in query_triples:\n","                e_h = triple[0]\n","                rel = triple[1]\n","                e_t = triple[2]\n","                while True:\n","                    noise = random.choice(candidates)\n","                    if noise in ent2id.keys():#ent2id.has_key(noise):\n","                        if (noise not in e1rel_e2[e_h+rel]) and noise != e_t:\n","                            break\n","                false_pairs.append([symbol2id[e_h], symbol2id[noise]])\n","                false_left.append(ent2id[e_h])\n","                false_right.append(ent2id[noise])\n","\n","        yield support_pairs, query_pairs, false_pairs, support_left, support_right, query_left, query_right, false_left, false_right\n","\n","\n","def centroid_generate(dataset, relation_name, symbol2id, ent2id, train_tasks, rela2label):\n","\n","    all_test_triples = train_tasks[relation_name]\n","\n","    query_triples = all_test_triples\n","\n","    query_pairs = [[symbol2id[triple[0]], symbol2id[triple[2]]] for triple in query_triples]\n","\n","    query_left = [ent2id[triple[0]] for triple in query_triples]\n","    query_right = [ent2id[triple[2]] for triple in query_triples]\n","\n","    return query_pairs, query_left, query_right, rela2label[relation_name]\n","\n","\n","def train_generate_decription(dataset, train_tasks, batch_size, symbol2id, ent2id, e1rel_e2, rel2id, args, rela2label, rela_matrix):\n","    # print(\"train_generate_description\", seed)\n","    # random.seed(seed)\n","    print('##LOADING TRAINING DATA')\n","    # train_tasks = json.load(open(dataset + 'train_tasks.json'))\n","    print('##LOADING CANDIDATES')\n","    rel2candidates = json.load(open(dataset + '/rel2candidates_all.json'))\n","    # task_pool = list(train_tasks.keys())\n","    task_pool = sorted(train_tasks.keys())  # ensure the readout is the same\n","\n","    # print(task_pool)\n","\n","    while True:\n","        rel_batch, query_pairs, query_left, query_right, false_pairs, false_left, false_right, labels = [], [], [], [], [], [], [], []\n","        random.shuffle(task_pool)\n","        if len(rel2candidates[task_pool[0]]) <= 20:\n","            continue\n","        if len(rel2candidates[task_pool[1]]) <= 20:\n","            continue\n","        for query in task_pool[:args.gan_batch_rela]:\n","            # print(query)\n","            relation_id = rel2id[query]\n","            candidates = rel2candidates[query]\n","\n","            if args.dataset == 'Wiki':\n","                if len(candidates) <= 20:\n","                    # print 'not enough candidates'\n","                    continue\n","\n","            train_and_test = train_tasks[query]\n","\n","            random.shuffle(train_and_test)\n","\n","            all_test_triples = train_and_test\n","\n","            if len(all_test_triples) == 0:\n","                continue\n","\n","            # print(\"all test triples num:\", len(all_test_triples))\n","\n","            if len(all_test_triples) < batch_size:\n","                query_triples = [random.choice(all_test_triples) for _ in range(batch_size)]\n","            else:\n","                query_triples = random.sample(all_test_triples, batch_size)\n","\n","            query_pairs += [[symbol2id[triple[0]], symbol2id[triple[2]]] for triple in query_triples]\n","\n","            query_left += [ent2id[triple[0]] for triple in query_triples]\n","            query_right += [ent2id[triple[2]] for triple in query_triples]\n","\n","            label = rela2label[query]\n","\n","            # generate negative samples\n","            false_pairs_ = []\n","            false_left_ = []\n","            false_right_ = []\n","            for triple in query_triples:\n","                e_h = triple[0]\n","                rel = triple[1]\n","                e_t = triple[2]\n","                while True:\n","                    noise = random.choice(candidates)\n","                    if noise in ent2id.keys(): # ent2id.has_key(noise):\n","                        if (noise not in e1rel_e2[e_h+rel]) and noise != e_t:\n","                            break\n","                false_pairs_.append([symbol2id[e_h], symbol2id[noise]])\n","                false_left_.append(ent2id[e_h])\n","                false_right_.append(ent2id[noise])\n","\n","            false_pairs += false_pairs_\n","            false_left += false_left_\n","            false_right += false_right_\n","\n","\n","            rel_batch += [rel2id[query] for _ in range(batch_size)]\n","\n","            labels += [rela2label[query]] * batch_size\n","\n","        yield rela_matrix[rel_batch], query_pairs, query_left, query_right, false_pairs, false_left, false_right, labels\n","\n","def load_semantic_embed(data_path, dataset, type):\n","    \"\"\"\n","    Load Semantic Embeddings.\n","    \"\"\"\n","\n","    file_name = ''\n","    file_path = os.path.join(data_path, 'semantic_embeddings')\n","    if dataset == 'NELL':\n","        if type == 'rdfs':\n","            file_name = os.path.join(file_path, 'rela_matrix_rdfs_55000.npz')\n","        elif type == 'rdfs_hie':\n","            file_name = os.path.join(file_path, 'rela_matrix_rdfs_hie_60000.npz')\n","        elif type == 'rdfs_cons':\n","            file_name = os.path.join(file_path, 'rela_matrix_rdfs_cons_60000.npz')\n","        elif type == 'text':\n","            file_name = os.path.join(file_path, 'rela_matrix_text.npz')\n","        elif type == 'rdfs_text':\n","            file_name = os.path.join(file_path, 'rela_matrix_rdfs_55000_text140.npz')\n","        else:\n","            print(\"WARNING: invalid semantic embeddings type\")\n","    elif dataset == 'Wiki':\n","        if type == 'rdfs':\n","            file_name = os.path.join(file_path, 'rela_matrix_rdfs_65000.npz')\n","        elif type == 'rdfs_hie':\n","            file_name = os.path.join(file_path, 'rela_matrix_rdfs_hie_60000.npz')\n","        elif type == 'rdfs_cons':\n","            file_name = os.path.join(file_path, 'rela_matrix_rdfs_cons_60000.npz')\n","        elif type == 'text':\n","            file_name = os.path.join(file_path, 'rela_matrix_text.npz')\n","        elif type == 'rdfs_text':\n","            file_name = os.path.join(file_path, 'rela_matrix_rdfs_65000_text140.npz')\n","        else:\n","            print(\"WARNING: invalid semantic embeddings type\")\n","\n","    if file_name:\n","        rela_embeddings = np.load(file_name)['relaM'].astype('float32')\n","\n","\n","    else:\n","        print('WARNING: invalid semantic embeddings file path')\n","    return rela_embeddings"],"metadata":{"id":"hoQknvUv3_iG","executionInfo":{"status":"ok","timestamp":1666194110426,"user_tz":-480,"elapsed":21,"user":{"displayName":"黄雨峰","userId":"10355830370640481145"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["**4. Additional Modules for Feature Encoder**"],"metadata":{"id":"h77m2Y-VzDpI"}},{"cell_type":"code","source":["def gaussian_noise(x, sigma=0.1, mean=0, stddev=1, is_training=True):\n","    if is_training:\n","        noise = Variable(x.data.new(x.size()).normal_(mean, stddev))\n","        noise = sigma * noise\n","        return x + noise\n","    return x\n","\n","\n","\n","class Path(nn.Module):\n","    \"\"\"convolution to encode every paths beween an entity pair\"\"\"\n","    def __init__(self, input_dim, num_symbols, use_pretrain=True, embed_path='', dropout=0.5, k_sizes = [3], k_num=100):\n","        '''\n","        Parameters:\n","        input_dim: size of relation/entity embeddings\n","        num_symbols: total number of entities and relations\n","        use_pretraIn: use pretrained KB embeddings or not\n","        '''\n","        super(Path, self).__init__()\n","        self.symbol_emb = nn.Embedding(num_symbols + 1, input_dim, padding_idx=num_symbols)\n","        self.k_sizes = k_sizes\n","        self.k_num = k_num\n","\n","        if use_pretrain:\n","            emb_np = np.loadtxt(embed_path)\n","            self.symbol_emb.weight.data.copy_(torch.from_numpy(emb_np))\n","            self.symbol_emb.weight.requires_grad = False\n","\n","        self.convs = nn.ModuleList([nn.Conv2d(1,self.k_num, (k, input_dim)) for k in self.k_sizes])\n","\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, path):\n","        '''\n","        Inputs:\n","        path: batch * max_len(7)\n","        '''\n","        path = self.symbol_emb(path)\n","        path = path.unsqueeze(1) # (B, 1, W, D)\n","\n","        convs = [F.relu(conv(path)).squeeze(3) for conv in self.convs] # every element (B, 100, W-(k-1))\n","        pools = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in convs]\n","\n","        path = torch.cat(pools, 1) # (B, num_k * c_out)\n","        path = self.dropout(path)\n","\n","        return path\n","\n","class ScaledDotProductAttention(nn.Module):\n","    ''' Scaled Dot-Product Attention '''\n","\n","    def __init__(self, d_model, attn_dropout=0.1):\n","        super(ScaledDotProductAttention, self).__init__()\n","        self.temper = np.power(d_model, 0.5)\n","        self.dropout = nn.Dropout(attn_dropout)\n","        self.softmax = nn.Softmax(dim=-1)\n","\n","    def forward(self, q, k, v, attn_mask=None):\n","\n","        attn = torch.bmm(q, k.transpose(1, 2)) / self.temper\n","\n","        if attn_mask is not None:\n","\n","            assert attn_mask.size() == attn.size(), \\\n","                    'Attention mask shape {} mismatch ' \\\n","                    'with Attention logit tensor shape ' \\\n","                    '{}.'.format(attn_mask.size(), attn.size())\n","\n","            attn.data.masked_fill_(attn_mask, -float('inf'))\n","\n","        attn = self.softmax(attn)\n","        attn = self.dropout(attn)\n","        output = torch.bmm(attn, v)\n","\n","        return output, attn\n","\n","class LayerNormalization(nn.Module):\n","    ''' Layer normalization module '''\n","\n","    def __init__(self, d_hid, eps=1e-3):\n","        super(LayerNormalization, self).__init__()\n","\n","        self.eps = eps\n","        self.a_2 = nn.Parameter(torch.ones(d_hid), requires_grad=True)\n","        self.b_2 = nn.Parameter(torch.zeros(d_hid), requires_grad=True)\n","\n","    def forward(self, z):\n","        if z.size(1) == 1:\n","            return z\n","\n","        mu = torch.mean(z, keepdim=True, dim=-1)\n","        sigma = torch.std(z, keepdim=True, dim=-1)\n","        ln_out = (z - mu.expand_as(z)) / (sigma.expand_as(z) + self.eps)\n","        ln_out = ln_out * self.a_2.expand_as(ln_out) + self.b_2.expand_as(ln_out)\n","\n","        return ln_out\n","\n","class MultiHeadAttention(nn.Module):\n","    ''' Multi-Head Attention module '''\n","\n","    def __init__(self, n_head, d_model, d_k, d_v, dropout=0.1):\n","        super(MultiHeadAttention, self).__init__()\n","\n","        self.n_head = n_head\n","        self.d_k = d_k\n","        self.d_v = d_v\n","\n","        self.w_qs = nn.Parameter(torch.FloatTensor(n_head, d_model, d_k))\n","        self.w_ks = nn.Parameter(torch.FloatTensor(n_head, d_model, d_k))\n","        self.w_vs = nn.Parameter(torch.FloatTensor(n_head, d_model, d_v))\n","\n","        self.attention = ScaledDotProductAttention(d_model)\n","        self.layer_norm = LayerNormalization(d_model)\n","\n","        self.proj = nn.Linear(n_head*d_v, d_model)\n","        init.xavier_normal_(self.proj.weight)\n","\n","        self.dropout = nn.Dropout(dropout)\n","\n","        init.xavier_normal_(self.w_qs)\n","        init.xavier_normal_(self.w_ks)\n","        init.xavier_normal_(self.w_vs)\n","\n","    def forward(self, q, k, v, attn_mask=None):\n","\n","        d_k, d_v = self.d_k, self.d_v\n","        n_head = self.n_head\n","\n","        residual = q\n","\n","        mb_size, len_q, d_model = q.size()\n","        mb_size, len_k, d_model = k.size()\n","        mb_size, len_v, d_model = v.size()\n","\n","        # treat as a (n_head) size batch\n","        q_s = q.repeat(n_head, 1, 1).view(n_head, -1, d_model) # n_head x (mb_size*len_q) x d_model\n","        k_s = k.repeat(n_head, 1, 1).view(n_head, -1, d_model) # n_head x (mb_size*len_k) x d_model\n","        v_s = v.repeat(n_head, 1, 1).view(n_head, -1, d_model) # n_head x (mb_size*len_v) x d_model\n","\n","        # treat the result as a (n_head * mb_size) size batch\n","        q_s = torch.bmm(q_s, self.w_qs).view(-1, len_q, d_k)   # (n_head*mb_size) x len_q x d_k\n","        k_s = torch.bmm(k_s, self.w_ks).view(-1, len_k, d_k)   # (n_head*mb_size) x len_k x d_k\n","        v_s = torch.bmm(v_s, self.w_vs).view(-1, len_v, d_v)   # (n_head*mb_size) x len_v x d_v\n","\n","        # perform attention, result size = (n_head * mb_size) x len_q x d_v\n","        if attn_mask:\n","            outputs, attns = self.attention(q_s, k_s, v_s, attn_mask=attn_mask.repeat(n_head, 1, 1))\n","        else:\n","            outputs, attns = self.attention(q_s, k_s, v_s, attn_mask=None)\n","\n","        # back to original mb_size batch, result size = mb_size x len_q x (n_head*d_v)\n","        outputs = torch.cat(torch.split(outputs, mb_size, dim=0), dim=-1)\n","\n","        # project back to residual size\n","        outputs = self.proj(outputs)\n","        outputs = self.dropout(outputs)\n","\n","        return self.layer_norm(outputs + residual), attns\n","\n","class PositionwiseFeedForward(nn.Module):\n","    ''' A two-feed-forward-layer module '''\n","\n","    def __init__(self, d_hid, d_inner_hid, dropout=0.1):\n","        super(PositionwiseFeedForward, self).__init__()\n","        self.w_1 = nn.Conv1d(d_hid, d_inner_hid, 1) # position-wise\n","        self.w_2 = nn.Conv1d(d_inner_hid, d_hid, 1) # position-wise\n","        self.layer_norm = LayerNormalization(d_hid)\n","        self.dropout = nn.Dropout(dropout)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        residual = x\n","        output = self.relu(self.w_1(x.transpose(1, 2)))\n","        output = self.w_2(output).transpose(2, 1)\n","        output = self.dropout(output)\n","        return self.layer_norm(output + residual)\n","\n","class SupportEncoder(nn.Module):\n","    \"\"\"docstring for SupportEncoder\"\"\"\n","    def __init__(self, d_model, d_inner, dropout=0.1):\n","        super(SupportEncoder, self).__init__()\n","        self.proj1 = nn.Linear(d_model, d_inner)\n","        self.proj2 = nn.Linear(d_inner, d_model)\n","        self.layer_norm = LayerNormalization(d_model)\n","\n","        init.xavier_normal_(self.proj1.weight)\n","        init.xavier_normal_(self.proj2.weight)\n","\n","        self.dropout = nn.Dropout(dropout)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        residual = x\n","        output = self.relu(self.proj1(x))\n","        output = self.dropout(self.proj2(output))\n","        return self.layer_norm(output + residual)\n","\n","\n","class EncoderLayer(nn.Module):\n","    ''' Compose with two layers '''\n","\n","    def __init__(self, d_model, d_inner_hid, n_head, d_k, d_v, dropout=0.1):\n","        super(EncoderLayer, self).__init__()\n","        self.slf_attn = MultiHeadAttention(\n","            n_head, d_model, d_k, d_v, dropout=dropout)\n","        # self.pos_ffn = PositionwiseFeedForward(d_model, d_inner_hid, dropout=dropout)\n","\n","    def forward(self, enc_input, slf_attn_mask=None):\n","        enc_output, enc_slf_attn = self.slf_attn(\n","            enc_input, enc_input, enc_input, attn_mask=slf_attn_mask)\n","        # enc_output = self.pos_ffn(enc_output)\n","        return enc_output, enc_slf_attn\n","\n","\n","class ContextAwareEncoder(nn.Module):\n","    \"\"\"Use self-attention here\"\"\"\n","    def __init__(self, num_layers, d_model, d_inner_hid, n_head, d_k, d_v, dropout = 0.1):\n","        super(ContextAwareEncoder, self).__init__()\n","        self.num_layers = num_layers\n","        #\n","        self.layer_stack = nn.ModuleList([EncoderLayer(d_model, d_inner_hid, n_head, d_k, d_v, dropout=dropout) for _ in range(self.num_layers)])\n","\n","    def forward(self, elements, enc_slf_attn_mask=None):\n","        enc_output = elements\n","        for enc_layer in self.layer_stack:\n","            enc_output, enc_slf_attn = enc_layer(\n","                enc_output, slf_attn_mask=enc_slf_attn_mask)\n","\n","        return enc_output\n","\n","class QueryEncoder(nn.Module):\n","    \"\"\"docstring for QueryEncoder\"\"\"\n","    def __init__(self, input_dim, process_step=4):\n","        super(QueryEncoder, self).__init__()\n","        self.input_dim = input_dim\n","        self.process_step = process_step\n","        # self.batch_size = batch_size\n","        self.process = nn.LSTMCell(input_dim, 2*input_dim)\n","\n","        # initialize the hidden states, TODO: try to train the initial state\n","        # self.h0 = Variable(torch.zeros(self.batch_size, 2*input_dim)).cuda()\n","        # self.c0 = Variable(torch.zeros(self.batch_size, 2*input_dim)).cuda()\n","\n","    def forward(self, support, query):\n","        '''\n","        support: (few, support_dim)\n","        query: (batch_size, query_dim)\n","        support_dim = query_dim\n","\n","        return:\n","        (batch_size, query_dim)\n","        '''\n","        assert support.size()[1] == query.size()[1]\n","\n","        if self.process_step == 0:\n","            return query\n","\n","        batch_size = query.size()[0]\n","        h_r = Variable(torch.zeros(batch_size, 2*self.input_dim)).cuda()\n","        c = Variable(torch.zeros(batch_size, 2*self.input_dim)).cuda()\n","        for step in range(self.process_step):\n","            h_r_, c = self.process(query, (h_r, c))\n","            h = query + h_r_[:,:self.input_dim] # (batch_size, query_dim)\n","            attn = F.softmax(torch.matmul(h, support.t()), dim=1)\n","            r = torch.matmul(attn, support) # (batch_size, support_dim)\n","            h_r = torch.cat((h, r), dim=1)\n","\n","        # return h_r_[:, :self.input_dim]\n","        return h"],"metadata":{"id":"SY9sp1Y94GOV","executionInfo":{"status":"ok","timestamp":1666194129645,"user_tz":-480,"elapsed":1523,"user":{"displayName":"黄雨峰","userId":"10355830370640481145"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["**5. Spectral Normalization from https://arxiv.org/abs/1802.05957**"],"metadata":{"id":"dlpLPStfzPVc"}},{"cell_type":"code","source":["class SpectralNorm(object):\n","    # Invariant before and after each forward call:\n","    #   u = normalize(W @ v)\n","    # NB: At initialization, this invariant is not enforced\n","\n","    _version = 1\n","    # At version 1:\n","    #   made  `W` not a buffer,\n","    #   added `v` as a buffer, and\n","    #   made eval mode use `W = u @ W_orig @ v` rather than the stored `W`.\n","\n","    def __init__(self, name='weight', n_power_iterations=1, dim=0, eps=1e-12):\n","        self.name = name\n","        self.dim = dim\n","        if n_power_iterations <= 0:\n","            raise ValueError('Expected n_power_iterations to be positive, but '\n","                             'got n_power_iterations={}'.format(n_power_iterations))\n","        self.n_power_iterations = n_power_iterations\n","        self.eps = eps\n","\n","    def reshape_weight_to_matrix(self, weight):\n","        weight_mat = weight\n","        if self.dim != 0:\n","            # permute dim to front\n","            weight_mat = weight_mat.permute(self.dim,\n","                                            *[d for d in range(weight_mat.dim()) if d != self.dim])\n","        height = weight_mat.size(0)\n","        return weight_mat.reshape(height, -1)\n","\n","    def compute_weight(self, module, do_power_iteration):\n","        # NB: If `do_power_iteration` is set, the `u` and `v` vectors are\n","        #     updated in power iteration **in-place**. This is very important\n","        #     because in `DataParallel` forward, the vectors (being buffers) are\n","        #     broadcast from the parallelized module to each module replica,\n","        #     which is a new module object created on the fly. And each replica\n","        #     runs its own spectral norm power iteration. So simply assigning\n","        #     the updated vectors to the module this function runs on will cause\n","        #     the update to be lost forever. And the next time the parallelized\n","        #     module is replicated, the same randomly initialized vectors are\n","        #     broadcast and used!\n","        #\n","        #     Therefore, to make the change propagate back, we rely on two\n","        #     important bahaviors (also enforced via tests):\n","        #       1. `DataParallel` doesn't clone storage if the broadcast tensor\n","        #          is alreay on correct device; and it makes sure that the\n","        #          parallelized module is already on `device[0]`.\n","        #       2. If the out tensor in `out=` kwarg has correct shape, it will\n","        #          just fill in the values.\n","        #     Therefore, since the same power iteration is performed on all\n","        #     devices, simply updating the tensors in-place will make sure that\n","        #     the module replica on `device[0]` will update the _u vector on the\n","        #     parallized module (by shared storage).\n","        #\n","        #    However, after we update `u` and `v` in-place, we need to **clone**\n","        #    them before using them to normalize the weight. This is to support\n","        #    backproping through two forward passes, e.g., the common pattern in\n","        #    GAN training: loss = D(real) - D(fake). Otherwise, engine will\n","        #    complain that variables needed to do backward for the first forward\n","        #    (i.e., the `u` and `v` vectors) are changed in the second forward.\n","        weight = getattr(module, self.name + '_orig')\n","        u = getattr(module, self.name + '_u')\n","        v = getattr(module, self.name + '_v')\n","        weight_mat = self.reshape_weight_to_matrix(weight)\n","\n","        if do_power_iteration:\n","            with torch.no_grad():\n","                for _ in range(self.n_power_iterations):\n","                    # Spectral norm of weight equals to `u^T W v`, where `u` and `v`\n","                    # are the first left and right singular vectors.\n","                    # This power iteration produces approximations of `u` and `v`.\n","                    v = normalize(torch.mv(weight_mat.t(), u), dim=0, eps=self.eps, out=v)\n","                    u = normalize(torch.mv(weight_mat, v), dim=0, eps=self.eps, out=u)\n","                if self.n_power_iterations > 0:\n","                    # See above on why we need to clone\n","                    u = u.clone()\n","                    v = v.clone()\n","\n","        sigma = torch.dot(u, torch.mv(weight_mat, v))\n","        weight = weight / sigma\n","        return weight\n","\n","    def remove(self, module):\n","        with torch.no_grad():\n","            weight = self.compute_weight(module, do_power_iteration=False)\n","        delattr(module, self.name)\n","        delattr(module, self.name + '_u')\n","        delattr(module, self.name + '_v')\n","        delattr(module, self.name + '_orig')\n","        module.register_parameter(self.name, torch.nn.Parameter(weight.detach()))\n","\n","    def __call__(self, module, inputs):\n","        setattr(module, self.name, self.compute_weight(module, do_power_iteration=module.training))\n","\n","    def _solve_v_and_rescale(self, weight_mat, u, target_sigma):\n","        # Tries to returns a vector `v` s.t. `u = normalize(W @ v)`\n","        # (the invariant at top of this class) and `u @ W @ v = sigma`.\n","        # This uses pinverse in case W^T W is not invertible.\n","        v = torch.chain_matmul(weight_mat.t().mm(weight_mat).pinverse(), weight_mat.t(), u.unsqueeze(1)).squeeze(1)\n","        return v.mul_(target_sigma / torch.dot(u, torch.mv(weight_mat, v)))\n","\n","    @staticmethod\n","    def apply(module, name, n_power_iterations, dim, eps):\n","        for k, hook in module._forward_pre_hooks.items():\n","            if isinstance(hook, SpectralNorm) and hook.name == name:\n","                raise RuntimeError(\"Cannot register two spectral_norm hooks on \"\n","                                   \"the same parameter {}\".format(name))\n","\n","        fn = SpectralNorm(name, n_power_iterations, dim, eps)\n","        weight = module._parameters[name]\n","\n","        with torch.no_grad():\n","            weight_mat = fn.reshape_weight_to_matrix(weight)\n","\n","            h, w = weight_mat.size()\n","            # randomly initialize `u` and `v`\n","            u = normalize(weight.new_empty(h).normal_(0, 1), dim=0, eps=fn.eps)\n","            v = normalize(weight.new_empty(w).normal_(0, 1), dim=0, eps=fn.eps)\n","\n","        delattr(module, fn.name)\n","        module.register_parameter(fn.name + \"_orig\", weight)\n","        # We still need to assign weight back as fn.name because all sorts of\n","        # things may assume that it exists, e.g., when initializing weights.\n","        # However, we can't directly assign as it could be an nn.Parameter and\n","        # gets added as a parameter. Instead, we register weight.data as a plain\n","        # attribute.\n","        setattr(module, fn.name, weight.data)\n","        module.register_buffer(fn.name + \"_u\", u)\n","        module.register_buffer(fn.name + \"_v\", v)\n","\n","        module.register_forward_pre_hook(fn)\n","\n","        module._register_state_dict_hook(SpectralNormStateDictHook(fn))\n","        module._register_load_state_dict_pre_hook(SpectralNormLoadStateDictPreHook(fn))\n","        return fn\n","\n","\n","# This is a top level class because Py2 pickle doesn't like inner class nor an\n","# instancemethod.\n","class SpectralNormLoadStateDictPreHook(object):\n","    # See docstring of SpectralNorm._version on the changes to spectral_norm.\n","    def __init__(self, fn):\n","        self.fn = fn\n","\n","    # For state_dict with version None, (assuming that it has gone through at\n","    # least one training forward), we have\n","    #\n","    #    u = normalize(W_orig @ v)\n","    #    W = W_orig / sigma, where sigma = u @ W_orig @ v\n","    #\n","    # To compute `v`, we solve `W_orig @ x = u`, and let\n","    #    v = x / (u @ W_orig @ x) * (W / W_orig).\n","    def __call__(self, state_dict, prefix, local_metadata, strict,\n","                 missing_keys, unexpected_keys, error_msgs):\n","        fn = self.fn\n","        version = local_metadata.get('spectral_norm', {}).get(fn.name + '.version', None)\n","        if version is None or version < 1:\n","            with torch.no_grad():\n","                weight_orig = state_dict[prefix + fn.name + '_orig']\n","                weight = state_dict.pop(prefix + fn.name)\n","                sigma = (weight_orig / weight).mean()\n","                weight_mat = fn.reshape_weight_to_matrix(weight_orig)\n","                u = state_dict[prefix + fn.name + '_u']\n","                v = fn._solve_v_and_rescale(weight_mat, u, sigma)\n","                state_dict[prefix + fn.name + '_v'] = v\n","\n","\n","# This is a top level class because Py2 pickle doesn't like inner class nor an\n","# instancemethod.\n","class SpectralNormStateDictHook(object):\n","    # See docstring of SpectralNorm._version on the changes to spectral_norm.\n","    def __init__(self, fn):\n","        self.fn = fn\n","\n","    def __call__(self, module, state_dict, prefix, local_metadata):\n","        if 'spectral_norm' not in local_metadata:\n","            local_metadata['spectral_norm'] = {}\n","        key = self.fn.name + '.version'\n","        if key in local_metadata['spectral_norm']:\n","            raise RuntimeError(\"Unexpected key in metadata['spectral_norm']: {}\".format(key))\n","        local_metadata['spectral_norm'][key] = self.fn._version\n","\n","\n","def spectral_norm(module, name='weight', n_power_iterations=1, eps=1e-12, dim=None):\n","    r\"\"\"Applies spectral normalization to a parameter in the given module.\n","\n","    .. math::\n","        \\mathbf{W}_{SN} = \\dfrac{\\mathbf{W}}{\\sigma(\\mathbf{W})},\n","        \\sigma(\\mathbf{W}) = \\max_{\\mathbf{h}: \\mathbf{h} \\ne 0} \\dfrac{\\|\\mathbf{W} \\mathbf{h}\\|_2}{\\|\\mathbf{h}\\|_2}\n","\n","    Spectral normalization stabilizes the training of discriminators (critics)\n","    in Generative Adversarial Networks (GANs) by rescaling the weight tensor\n","    with spectral norm :math:`\\sigma` of the weight matrix calculated using\n","    power iteration method. If the dimension of the weight tensor is greater\n","    than 2, it is reshaped to 2D in power iteration method to get spectral\n","    norm. This is implemented via a hook that calculates spectral norm and\n","    rescales weight before every :meth:`~Module.forward` call.\n","\n","    See `Spectral Normalization for Generative Adversarial Networks`_ .\n","\n","    .. _`Spectral Normalization for Generative Adversarial Networks`: https://arxiv.org/abs/1802.05957\n","\n","    Args:\n","        module (nn.Module): containing module\n","        name (str, optional): name of weight parameter\n","        n_power_iterations (int, optional): number of power iterations to\n","            calculate spectral norm\n","        eps (float, optional): epsilon for numerical stability in\n","            calculating norms\n","        dim (int, optional): dimension corresponding to number of outputs,\n","            the default is 0, except for modules that are instances of\n","            ConvTranspose1/2/3d, when it is 1\n","\n","    Returns:\n","        The original module with the spectral norm hook\n","\n","    Example::\n","\n","        >>> m = spectral_norm(nn.Linear(20, 40))\n","        Linear (20 -> 40)\n","        >>> m.weight_u.size()\n","        torch.Size([20])\n","\n","    \"\"\"\n","    if dim is None:\n","        if isinstance(module, (torch.nn.ConvTranspose1d,\n","                               torch.nn.ConvTranspose2d,\n","                               torch.nn.ConvTranspose3d)):\n","            dim = 1\n","        else:\n","            dim = 0\n","    SpectralNorm.apply(module, name, n_power_iterations, dim, eps)\n","    return module\n","\n","\n","def remove_spectral_norm(module, name='weight'):\n","    r\"\"\"Removes the spectral normalization reparameterization from a module.\n","\n","    Args:\n","        module (nn.Module): containing module\n","        name (str, optional): name of weight parameter\n","\n","    Example:\n","        >>> m = spectral_norm(nn.Linear(40, 10))\n","        >>> remove_spectral_norm(m)\n","    \"\"\"\n","    for k, hook in module._forward_pre_hooks.items():\n","        if isinstance(hook, SpectralNorm) and hook.name == name:\n","            hook.remove(module)\n","            del module._forward_pre_hooks[k]\n","            return module\n","\n","    raise ValueError(\"spectral_norm of '{}' not found in {}\".format(\n","        name, module))"],"metadata":{"id":"qdmoDNeu4Qxu","executionInfo":{"status":"ok","timestamp":1666194146314,"user_tz":-480,"elapsed":4,"user":{"displayName":"黄雨峰","userId":"10355830370640481145"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["**6. Models, including Feature Extractor, Generator and Discriminator**"],"metadata":{"id":"lSX4b-1EyYoK"}},{"cell_type":"code","source":["def weights_init(m):\n","    classname = m.__class__.__name__\n","    if 'Linear' in classname:\n","        init.xavier_normal_(m.weight.data)\n","        init.constant_(m.bias, 0.0)\n","class Extractor(nn.Module):\n","    \"\"\"\n","    Matching metric based on KB Embeddings\n","    \"\"\"\n","\n","    def __init__(self, embed_dim, num_symbols, embed=None):\n","        super(Extractor, self).__init__()\n","        self.embed_dim = int(embed_dim)\n","        self.pad_idx = num_symbols\n","        self.symbol_emb = nn.Embedding(num_symbols + 1, embed_dim, padding_idx=num_symbols)\n","        self.num_symbols = num_symbols\n","\n","        self.gcn_w = nn.Linear(self.embed_dim, int(self.embed_dim / 2))\n","        self.gcn_b = nn.Parameter(torch.FloatTensor(self.embed_dim))\n","\n","        self.fc1 = nn.Linear(self.embed_dim, int(self.embed_dim / 2))\n","        self.fc2 = nn.Linear(self.embed_dim, int(self.embed_dim / 2))\n","\n","        self.dropout = nn.Dropout(0.2)\n","        self.dropout_e = nn.Dropout(0.2)\n","\n","        self.symbol_emb.weight.data.copy_(torch.from_numpy(embed))\n","\n","        self.symbol_emb.weight.requires_grad = False\n","\n","        d_model = self.embed_dim * 2\n","        self.support_encoder = SupportEncoder(d_model, 2 * d_model, dropout=0.2)\n","        # self.query_encoder = QueryEncoder(d_model, process_steps)\n","\n","    def neighbor_encoder(self, connections, num_neighbors):\n","        '''\n","        connections: (batch, 200, 2)\n","        num_neighbors: (batch,)\n","        '''\n","        num_neighbors = num_neighbors.unsqueeze(1)\n","        entities = connections[:, :, 1].squeeze(-1)\n","        ent_embeds = self.dropout(self.symbol_emb(entities))  # (batch, 50, embed_dim)\n","        concat_embeds = ent_embeds\n","\n","        out = self.gcn_w(concat_embeds)\n","        out = torch.sum(out, dim=1)  # (batch, embed_dim)\n","        out = out / num_neighbors\n","        return out.tanh()\n","\n","    def entity_encoder(self, entity1, entity2):\n","        entity1 = self.dropout_e(entity1)\n","        entity2 = self.dropout_e(entity2)\n","        entity1 = self.fc1(entity1)\n","        entity2 = self.fc2(entity2)\n","        entity = torch.cat((entity1, entity2), dim=-1)\n","        return entity.tanh()  # (batch, embed_dim)\n","\n","    def forward(self, query, support, query_meta=None, support_meta=None):\n","        '''\n","        query: (batch_size, 2)\n","        support: (few, 2)\n","        return: (batch_size, )\n","        '''\n","        query_left_connections, query_left_degrees, query_right_connections, query_right_degrees = query_meta\n","        support_left_connections, support_left_degrees, support_right_connections, support_right_degrees = support_meta\n","\n","        query_e1 = self.symbol_emb(query[:, 0])  # (batch, embed_dim)\n","        query_e2 = self.symbol_emb(query[:, 1])  # (batch, embed_dim)\n","        query_e = self.entity_encoder(query_e1, query_e2)\n","\n","        support_e1 = self.symbol_emb(support[:, 0])  # (batch, embed_dim)\n","        support_e2 = self.symbol_emb(support[:, 1])  # (batch, embed_dim)\n","        support_e = self.entity_encoder(support_e1, support_e2)\n","\n","        query_left = self.neighbor_encoder(query_left_connections, query_left_degrees)\n","        query_right = self.neighbor_encoder(query_right_connections, query_right_degrees)\n","\n","        support_left = self.neighbor_encoder(support_left_connections, support_left_degrees)\n","        support_right = self.neighbor_encoder(support_right_connections, support_right_degrees)\n","\n","        query_neighbor = torch.cat((query_left, query_e, query_right), dim=-1)  # tanh\n","        support_neighbor = torch.cat((support_left, support_e, support_right), dim=-1)  # tanh\n","\n","        support = support_neighbor\n","        query = query_neighbor\n","\n","        support_g = self.support_encoder(support)  # 1 * 100\n","        query_g = self.support_encoder(query)\n","\n","        support_g = torch.mean(support_g, dim=0, keepdim=True)\n","\n","        # cosine similarity\n","        matching_scores = torch.matmul(query_g, support_g.t()).squeeze()\n","\n","        return query_g, matching_scores\n","\n","\n","class Generator(nn.Module):\n","\n","    def __init__(self, args, dropout=0.5):\n","        super(Generator, self).__init__()\n","        input_dim = args.input_dim\n","        self.noise_dim = args.noise_dim\n","\n","        self.fc1_dim = args.fc1_dim\n","        self.ep_dim = args.ep_dim\n","\n","\n","        fc1 = nn.Linear(input_dim + self.noise_dim, self.fc1_dim)\n","        self.fc1 = spectral_norm(fc1)\n","\n","        fc2 = nn.Linear(self.fc1_dim, self.ep_dim)\n","        self.fc2 = spectral_norm(fc2)\n","\n","        self.layer_norm = LayerNormalization(self.ep_dim)\n","\n","    def forward(self, description, noise):\n","        x_noise = torch.cat([noise, description], 1)\n","        x_noise = self.fc1(x_noise)\n","        false = self.fc2(x_noise)\n","        false = self.layer_norm(false)\n","\n","        return false\n","\n","\n","class Discriminator(nn.Module):\n","    def __init__(self, args, dropout=0.3):\n","        super(Discriminator, self).__init__()\n","        fc2_dim = args.ep_dim\n","        fc_middle = nn.Linear(fc2_dim, fc2_dim)\n","        self.fc_middle = spectral_norm(fc_middle)\n","\n","        fc_TF = nn.Linear(fc2_dim, 1)  # True or False\n","        self.fc_TF = spectral_norm(fc_TF)\n","\n","        self.layer_norm = LayerNormalization(fc2_dim)\n","\n","\n","    def forward(self, ep_vec, centroid_matrix):\n","        middle_vec = F.leaky_relu(self.fc_middle(ep_vec))\n","        middle_vec = self.layer_norm(middle_vec)\n","\n","        centroid_matrix = F.leaky_relu(self.fc_middle(centroid_matrix))\n","        centroid_matrix = self.layer_norm(centroid_matrix)\n","\n","        # determine True or False\n","        logit_TF = self.fc_TF(middle_vec)\n","\n","        # determine label\n","        class_scores = torch.matmul(middle_vec, centroid_matrix.t())\n","\n","        return middle_vec, logit_TF, class_scores"],"metadata":{"id":"iz0xC5Cx4MsC","executionInfo":{"status":"ok","timestamp":1666194162384,"user_tz":-480,"elapsed":4,"user":{"displayName":"黄雨峰","userId":"10355830370640481145"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["**7. Model Training and Evaluation**"],"metadata":{"id":"y2Gy_WRMzVGp"}},{"cell_type":"code","source":["def calc_gradient_penalty(netD, real_data, fake_data, batchsize, centroid_matrix):\n","    alpha = torch.rand(batchsize, 1)\n","    alpha = alpha.expand(real_data.size())\n","    alpha = alpha.cuda()\n","\n","    interpolates = alpha * real_data + ((1 - alpha) * fake_data)\n","    interpolates = interpolates.cuda()\n","    interpolates = torch.autograd.Variable(interpolates, requires_grad=True)\n","\n","    _, disc_interpolates, _ = netD(interpolates, centroid_matrix)\n","\n","    gradients = torch.autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n","                              grad_outputs=torch.ones(disc_interpolates.size()).cuda(),\n","                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n","    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * 10 #opt.GP_LAMBDA\n","    return gradient_penalty\n","\n","def reset_grad(nets):\n","    for net in nets:\n","        net.zero_grad()\n","\n","\n","class Trainer(object):\n","\n","    def __init__(self, args):\n","        super(Trainer, self).__init__()\n","        for k, v in vars(args).items():setattr(self, k, v)\n","        self.args = args\n","\n","\n","        self.train_tasks = json.load(open(os.path.join(args.data_path, 'datasplit', 'train_tasks.json')))\n","        self.rel2id = json.load(open(os.path.join(args.data_path, 'relation2ids')))\n","\n","        self.rela_matrix = load_semantic_embed(args.data_path, args.dataset, args.semantic_type)\n","        self.args.input_dim = self.rela_matrix.shape[1]\n","\n","\n","        self.ent2id = json.load(open(os.path.join(args.data_path, 'entity2id')))\n","\n","        print('##LOADING CANDIDATES ENTITIES##')\n","        self.rel2candidates = json.load(open(os.path.join(args.data_path, 'rel2candidates_all.json')))\n","\n","        # load answer dict\n","        self.e1rel_e2 = defaultdict(list)\n","        self.e1rel_e2 = json.load(open(os.path.join(args.data_path, 'e1rel_e2_all.json')))\n","\n","\n","        noises = Variable(torch.randn(args.test_sample, args.noise_dim)).cuda()\n","        self.test_noises = 0.1 * noises\n","\n","        self.label_num = len(self.train_tasks.keys())\n","\n","        self.rela2label = dict()\n","        rela_sorted = sorted(list(self.train_tasks.keys()))\n","        for i, rela in enumerate(rela_sorted):\n","            self.rela2label[rela] = int(i)\n","\n","        print('##LOADING SYMBOL ID AND SYMBOL EMBEDDING')\n","        if args.load_trained_embed:\n","            self.load_embed()\n","        else:\n","            self.read_embed()\n","\n","\n","        self.num_symbols = len(self.symbol2id.keys()) - 1\n","        print(\"num symbols:\", self.num_symbols)\n","        self.pad_id = self.num_symbols\n","\n","        print('##DEFINE FEATURE EXTRACTOR')\n","        self.Extractor = Extractor(args.embed_dim, self.num_symbols, embed=self.symbol2vec)\n","        self.Extractor.cuda()\n","        self.Extractor.apply(weights_init)\n","        self.E_parameters = filter(lambda p: p.requires_grad, self.Extractor.parameters())\n","        self.optim_E = optim.Adam(self.E_parameters, lr=args.lr_E)\n","\n","        print('##DEFINE GENERATOR')\n","        self.Generator = Generator(self.args)\n","        self.Generator.cuda()\n","        self.Generator.apply(weights_init)\n","        self.G_parameters = filter(lambda p: p.requires_grad, self.Generator.parameters())\n","        self.optim_G = optim.Adam(self.G_parameters, lr=args.lr_G, betas=(0.5, 0.9))\n","        self.scheduler_G = optim.lr_scheduler.MultiStepLR(self.optim_G, milestones=[4000], gamma=0.2)\n","\n","        print('##DEFINE DISCRIMINATOR')\n","        self.Discriminator = Discriminator(self.args)\n","        self.Discriminator.cuda()\n","        self.Discriminator.apply(weights_init)\n","        self.D_parameters = filter(lambda p: p.requires_grad, self.Discriminator.parameters())\n","        self.optim_D = optim.Adam(self.D_parameters, lr=args.lr_D, betas=(0.5, 0.9))\n","        self.scheduler_D = optim.lr_scheduler.MultiStepLR(self.optim_D, milestones=[20000], gamma=0.2)\n","\n","        self.num_ents = len(self.ent2id.keys())\n","\n","        print('##BUILDING CONNECTION MATRIX')\n","        degrees = self.build_connection(max_=args.max_neighbor)\n","\n","\n","\n","    def ensure_path(self, path):\n","        print(path)\n","        if osp.exists(path):\n","            if input('{} exists, remove? ([y]/n)'.format(path)) != 'n':\n","                shutil.rmtree(path)\n","                os.mkdir(path)\n","        else:\n","            os.mkdir(path)\n","\n","    def load_embed(self):\n","\n","        symbol_id = {}\n","\n","        print('##LOADING PRE-TRAINED EMBEDDING')\n","        if self.args.embed_model in ['DistMult', 'TransE']:\n","            embed_all = np.load(os.path.join(self.args.data_path, self.args.embed_model + '_embed.npz'))\n","            ent_embed = embed_all['eM']\n","            rel_embed = embed_all['rM']\n","            print('    ent_embed shape is {}, the number of entity is {}'.format(ent_embed.shape,\n","                                                                                 len(self.ent2id.keys())))\n","            print('    rel_embed shape is {}, the number of relation is {}'.format(rel_embed.shape,\n","                                                                                   len(self.rel2id.keys())))\n","\n","            i = 0\n","            embeddings = []\n","            for key in self.rel2id.keys():\n","                if key not in ['', 'OOV']:\n","                    symbol_id[key] = i\n","                    i += 1\n","                    embeddings.append(list(rel_embed[self.rel2id[key], :]))\n","\n","            for key in self.ent2id.keys():\n","                if key not in ['', 'OOV']:\n","                    symbol_id[key] = i\n","                    i += 1\n","                    embeddings.append(list(ent_embed[self.ent2id[key], :]))\n","\n","            symbol_id['PAD'] = i\n","            embeddings.append(list(np.zeros((rel_embed.shape[1],))))\n","            embeddings = np.array(embeddings)\n","\n","\n","\n","            np.savez(os.path.join(self.args.data_path, 'Embed_used', self.args.embed_model), embeddings)\n","            json.dump(symbol_id, open(os.path.join(self.args.data_path, 'Embed_used', self.args.embed_model + '2id'), 'w'))\n","\n","            self.symbol2id = symbol_id\n","            self.symbol2vec = embeddings\n","\n","    def read_embed(self):\n","        symbol_id = json.load(open(\n","                os.path.join(self.args.data_path, 'Embed_used', self.args.embed_model + '2id')))\n","        embeddings = np.load(os.path.join(self.args.data_path, 'Embed_used', self.args.embed_model + '.npz'))['arr_0']\n","\n","        self.symbol2id = symbol_id\n","        self.symbol2vec = embeddings\n","\n","    #  build neighbor connection\n","    def build_connection(self, max_=100):\n","\n","        self.connections = (np.ones((self.num_ents, max_, 2)) * self.pad_id).astype(int)\n","        self.e1_rele2 = defaultdict(list)\n","        self.e1_degrees = defaultdict(int)\n","        # rel_list = list()\n","        with open(os.path.join(self.args.data_path, 'path_graph')) as f:\n","            lines = f.readlines()\n","            for line in tqdm(lines):\n","                e1, rel, e2 = line.rstrip().split()\n","                self.e1_rele2[e1].append((self.symbol2id[rel], self.symbol2id[e2]))\n","                self.e1_rele2[e2].append((self.symbol2id[rel], self.symbol2id[e1]))\n","\n","        # print(\"path graph relations:\", len(set(rel_list)))\n","        degrees = {}\n","        for ent, id_ in self.ent2id.items():\n","            neighbors = self.e1_rele2[ent]\n","            if len(neighbors) > max_:\n","                neighbors = neighbors[:max_]\n","            # degrees.append(len(neighbors))\n","            degrees[ent] = len(neighbors)\n","            self.e1_degrees[id_] = len(neighbors)  # add one for self conn\n","            for idx, _ in enumerate(neighbors):\n","                self.connections[id_, idx, 0] = _[0]\n","                self.connections[id_, idx, 1] = _[1]\n","        # print(self.connections[0])\n","        # json.dump(degrees, open(self.dataset + '/degrees', 'w'))\n","        # assert 1==2\n","\n","        return degrees\n","\n","    def save_pretrain(self):\n","        torch.save(self.Extractor.state_dict(), os.path.join(self.args.data_path, 'FE_models_trained', self.args.embed_model + '_Extractor'))\n","\n","\n","    def load_pretrain(self):\n","        self.Extractor.load_state_dict(torch.load(os.path.join(self.args.data_path, 'FE_models_trained', self.args.embed_model + '_Extractor'), map_location=lambda storage, loc: storage.cuda(self.args.gpu)))\n","        self.Extractor.eval()\n","\n","\n","\n","\n","    def save_model(self):\n","\n","        path = self.args.save_path\n","\n","        torch.save(self.Generator.state_dict(), os.path.join(path, self.args.embed_model + '_Generator'))\n","        torch.save(self.Discriminator.state_dict(), os.path.join(path, self.args.embed_model + '_Discriminator'))\n","\n","    def load_model(self):\n","        self.Generator.load_state_dict(torch.load(os.path.join(self.args.save_path, self.args.embed_model + '_Generator')))\n","        self.Discriminator.load_state_dict(torch.load(os.path.join(self.args.save_path, self.args.embed_model + '_Discriminator')))\n","\n","    def get_meta(self, left, right):\n","        left_connections = Variable(\n","            torch.LongTensor(np.stack([self.connections[_, :, :] for _ in left], axis=0))).cuda()\n","        left_degrees = Variable(torch.FloatTensor([self.e1_degrees[_] for _ in left])).cuda()\n","        right_connections = Variable(\n","            torch.LongTensor(np.stack([self.connections[_, :, :] for _ in right], axis=0))).cuda()\n","        right_degrees = Variable(torch.FloatTensor([self.e1_degrees[_] for _ in right])).cuda()\n","        return (left_connections, left_degrees, right_connections, right_degrees)\n","\n","    def pretrain_Extractor(self):\n","        print('\\n##PRETRAINING FEATURE EXTRACTOR ....')\n","        # self.ensure_path(self.args.save_path)\n","\n","        pretrain_losses = deque([], 100)\n","\n","        i = 0\n","        for data in Extractor_generate(self.args.manual_seed, self.args.data_path, self.train_tasks, self.pretrain_batch_size, self.symbol2id, self.ent2id,\n","                                       self.e1rel_e2, self.pretrain_few, self.pretrain_subepoch):\n","            i += 1\n","\n","            support, query, false, support_left, support_right, query_left, query_right, false_left, false_right = data\n","\n","            support_meta = self.get_meta(support_left, support_right)\n","            query_meta = self.get_meta(query_left, query_right)\n","            false_meta = self.get_meta(false_left, false_right)\n","\n","            support = Variable(torch.LongTensor(support)).cuda()\n","            query = Variable(torch.LongTensor(query)).cuda()\n","            false = Variable(torch.LongTensor(false)).cuda()\n","\n","            query_ep, query_scores = self.Extractor(query, support, query_meta, support_meta)\n","            false_ep, false_scores = self.Extractor(false, support, false_meta, support_meta)\n","\n","            margin_ = query_scores - false_scores\n","            pretrain_loss = F.relu(self.args.pretrain_margin - margin_).mean()\n","\n","            self.optim_E.zero_grad()\n","            pretrain_loss.backward()\n","            # self.scheduler.step()\n","            pretrain_losses.append(pretrain_loss.item())\n","\n","            if i % self.args.pretrain_loss_every == 0:\n","                print(\"Step: %d, Feature Extractor Pretraining loss: %.10f\" % (i, np.mean(pretrain_losses)))\n","\n","            self.optim_E.step()\n","\n","            if i > self.args.pretrain_times:\n","                break\n","\n","\n","\n","        self.save_pretrain()\n","        print('SAVE FEATURE EXTRACTOR PRETRAINING MODEL!!!')\n","\n","    def train(self):\n","        print('\\n##START ADVERSARIAL TRAINING...')\n","\n","        # Pretraining step to obtain reasonable real data embeddings\n","        if self.args.pretrain_feature_extractor:\n","            self.pretrain_Extractor()\n","            print('Finish Pretraining!\\n')\n","\n","        self.load_pretrain()\n","\n","\n","        self.centroid_matrix = torch.zeros((len(self.train_tasks), self.args.ep_dim))\n","        self.centroid_matrix = self.centroid_matrix.cuda()\n","\n","        for relname in self.train_tasks.keys():\n","            query, query_left, query_right, label_id = centroid_generate(self.args.data_path, relname, self.symbol2id,\n","                                                                         self.ent2id, self.train_tasks, self.rela2label)\n","            query_meta = self.get_meta(query_left, query_right)\n","            query = Variable(torch.LongTensor(query)).cuda()\n","            query_ep, _ = self.Extractor(query, query, query_meta, query_meta)\n","            self.centroid_matrix[label_id] = query_ep.data.mean(dim=0)\n","        self.centroid_matrix = Variable(self.centroid_matrix)\n","\n","        best_hits10 = 0.0\n","\n","        D_every = self.args.D_epoch * self.args.loss_every\n","        D_losses = deque([], D_every)\n","        D_real_losses, D_real_class_losses, D_fake_losses, D_fake_class_losses \\\n","            = deque([], D_every), deque([], D_every), deque([], D_every), deque([], D_every)\n","\n","        # loss_G_fake + loss_G_class + loss_VP\n","        G_every = self.args.G_epoch * self.args.loss_every\n","        G_losses = deque([], G_every)\n","        G_fake_losses, G_class_losses, G_VP_losses, G_real_class_losses \\\n","            = deque([], G_every), deque([], G_every), deque([], G_every), deque([], G_every)\n","\n","        G_data = train_generate_decription(self.args.data_path, self.train_tasks, self.args.G_batch_size, self.symbol2id, self.ent2id,\n","                                           self.e1rel_e2, self.rel2id, self.args, self.rela2label, self.rela_matrix)\n","\n","        nets = [self.Generator, self.Discriminator]\n","        reset_grad(nets)\n","\n","        for epoch in range(1, (self.args.train_times+1)):\n","\n","            # train Discriminator\n","            self.Discriminator.train()\n","            self.Generator.eval()\n","            for _ in range(self.args.D_epoch):  # D_epoch = 5\n","                ### Discriminator real part\n","                D_descriptions, query, query_left, query_right, D_false, D_false_left, D_false_right, D_labels = G_data.__next__()\n","\n","                # real part\n","                query_meta = self.get_meta(query_left, query_right)\n","                query = Variable(torch.LongTensor(query)).cuda()\n","                D_real, _ = self.Extractor(query, query, query_meta, query_meta)\n","\n","                # fake part\n","                noises = Variable(torch.randn(len(query), self.noise_dim)).cuda()\n","                D_descriptions = Variable(torch.FloatTensor(D_descriptions)).cuda()\n","                D_fake = self.Generator(D_descriptions, noises)\n","\n","                # neg part\n","                D_false_meta = self.get_meta(D_false_left, D_false_right)\n","                D_false = Variable(torch.LongTensor(D_false)).cuda()\n","                D_neg, _ = self.Extractor(D_false, D_false, D_false_meta, D_false_meta)\n","\n","                # generate Discriminator part vector\n","                centroid_matrix_ = self.centroid_matrix  # gaussian_noise(self.centroid_matrix)\n","                _, D_real_decision, D_real_class = self.Discriminator(D_real.detach(), centroid_matrix_)\n","                _, D_fake_decision, D_fake_class = self.Discriminator(D_fake.detach(), centroid_matrix_)\n","                _, _, D_neg_class = self.Discriminator(D_neg.detach(), self.centroid_matrix)\n","\n","                # real adversarial training loss\n","                loss_D_real = -torch.mean(D_real_decision)\n","\n","                # adversarial training loss\n","                loss_D_fake = torch.mean(D_fake_decision)\n","\n","                # real classification loss\n","                D_real_scores = D_real_class[range(len(query)), D_labels]\n","                D_neg_scores = D_neg_class[range(len(query)), D_labels]\n","                D_margin_real = D_real_scores - D_neg_scores\n","                loss_rela_class = F.relu(self.args.pretrain_margin - D_margin_real).mean()\n","\n","                # fake classification loss\n","                D_fake_scores = D_fake_class[range(len(query)), D_labels]\n","                D_margin_fake = D_fake_scores - D_neg_scores\n","                loss_fake_class = F.relu(self.args.pretrain_margin - D_margin_fake).mean()\n","\n","                grad_penalty = calc_gradient_penalty(self.Discriminator, D_real.data, D_fake.data, len(query),\n","                                                     self.centroid_matrix)\n","\n","                loss_D = loss_D_real + 0.5 * loss_rela_class + loss_D_fake + grad_penalty + 0.5 * loss_fake_class\n","\n","                # D_real_losses, D_real_class_losses, D_fake_losses, D_fake_class_losses\n","                D_losses.append(loss_D.item())\n","                D_real_losses.append(loss_D_real.item())\n","                D_real_class_losses.append(loss_rela_class.item())\n","                D_fake_losses.append(loss_D_fake.item())\n","                D_fake_class_losses.append(loss_fake_class.item())\n","\n","                loss_D.backward()\n","                self.scheduler_D.step()\n","                self.optim_D.step()\n","                reset_grad(nets)\n","\n","            # train Generator\n","            self.Discriminator.eval()\n","            self.Generator.train()\n","            for _ in range(self.args.G_epoch):  # G_epoch = 1\n","\n","                G_descriptions, query, query_left, query_right, G_false, G_false_left, G_false_right, G_labels = G_data.__next__()\n","\n","                # G sample\n","                noises = Variable(torch.randn(len(query), self.args.noise_dim)).cuda()\n","                G_descriptions = Variable(torch.FloatTensor(G_descriptions)).cuda()\n","                G_sample = self.Generator(G_descriptions, noises)  # to train G\n","\n","                # real data\n","                query_meta = self.get_meta(query_left, query_right)\n","                query = Variable(torch.LongTensor(query)).cuda()\n","                G_real, _ = self.Extractor(query, query, query_meta, query_meta)\n","\n","                # This negative for classification loss\n","                G_false_meta = self.get_meta(G_false_left, G_false_right)\n","                G_false = Variable(torch.LongTensor(G_false)).cuda()\n","                G_neg, _ = self.Extractor(G_false, G_false, G_false_meta,\n","                                          G_false_meta)  # just use Extractor to generate ep vector\n","\n","                # generate Discriminator part vector\n","                centroid_matrix_ = self.centroid_matrix\n","                _, G_decision, G_class = self.Discriminator(G_sample, centroid_matrix_)\n","                _, _, G_real_class = self.Discriminator(G_real.detach(), centroid_matrix_)\n","                _, _, G_neg_class = self.Discriminator(G_neg.detach(), centroid_matrix_)\n","\n","                # adversarial training loss\n","                loss_G_fake = - torch.mean(G_decision)\n","\n","                # G sample (fake) classification loss\n","                G_scores = G_class[range(len(query)), G_labels]\n","                G_neg_scores = G_neg_class[range(len(query)), G_labels]\n","                G_margin_ = G_scores - G_neg_scores\n","                loss_G_class = F.relu(self.args.pretrain_margin - G_margin_).mean()\n","\n","                # real classification loss\n","                G_real_scores = G_real_class[range(len(query)), G_labels]\n","                G_margin_real = G_real_scores - G_neg_scores\n","                loss_rela_class_ = F.relu(self.args.pretrain_margin - G_margin_real).mean()\n","\n","                # Visual Pivot Regularization\n","                count = 0\n","                loss_VP = Variable(torch.Tensor([0.0])).cuda()\n","                for i in range(len(self.train_tasks.keys())):\n","                    sample_idx = (np.array(G_labels) == i).nonzero()[0]\n","                    count += len(sample_idx)\n","                    if len(sample_idx) == 0:\n","                        loss_VP += 0.0\n","                    else:\n","                        G_sample_cls = G_sample[sample_idx, :]\n","                        loss_VP += (G_sample_cls.mean(dim=0) - self.centroid_matrix[i]).pow(2).sum().sqrt()\n","                assert count == len(query)\n","                loss_VP *= float(1.0 / self.args.gan_batch_rela)\n","\n","                # ||W||_2 regularization\n","                reg_loss = Variable(torch.Tensor([0.0])).cuda()\n","                if self.args.REG_W != 0:\n","                    for name, p in self.Generator.named_parameters():\n","                        if 'weight' in name:\n","                            reg_loss += p.pow(2).sum()\n","                    reg_loss.mul_(self.args.REG_W)\n","\n","                # ||W_z||21 regularization, make W_z sparse\n","                reg_Wz_loss = Variable(torch.Tensor([0.0])).cuda()\n","                if self.args.REG_Wz != 0:\n","                    Wz = self.Generator.fc1.weight\n","                    reg_Wz_loss = Wz.pow(2).sum(dim=0).sqrt().sum().mul(self.args.REG_Wz)\n","\n","                # Generator loss function\n","                loss_G = loss_G_fake + loss_G_class + 3.0 * loss_VP  # + reg_Wz_loss + reg_loss\n","\n","                # G_fake_losses, G_class_losses, G_VP_losses\n","                G_losses.append(loss_G.item())\n","                G_fake_losses.append(loss_G_fake.item())\n","                G_class_losses.append(loss_G_class.item())\n","                G_real_class_losses.append(loss_rela_class_.item())\n","                G_VP_losses.append(loss_VP.item())\n","\n","                loss_G.backward()\n","                self.scheduler_G.step()\n","                self.optim_G.step()\n","                reset_grad(nets)\n","\n","            if epoch % self.args.loss_every == 0:\n","                D_screen = [np.mean(D_real_losses), np.mean(D_real_class_losses), np.mean(D_fake_losses),\n","                            np.mean(D_fake_class_losses)]\n","                G_screen = [np.mean(G_fake_losses), np.mean(G_class_losses), np.mean(G_real_class_losses),\n","                            np.mean(G_VP_losses)]\n","                print(\"Epoch: %d, D_loss: %.2f [%.2f, %.2f, %.2f, %.2f], G_loss: %.2f [%.2f, %.2f, %.2f, %.2f]\" \\\n","                      % (\n","                      epoch, np.mean(D_losses), D_screen[0], D_screen[1], D_screen[2], D_screen[3], np.mean(G_losses),\n","                      G_screen[0], G_screen[1], G_screen[2], G_screen[3]))\n","\n","            # D_screen = [np.mean(D_real_losses), np.mean(D_real_class_losses), np.mean(D_fake_losses),\n","            #             np.mean(D_fake_class_losses)]\n","            # G_screen = [np.mean(G_fake_losses), np.mean(G_class_losses), np.mean(G_real_class_losses),\n","            #             np.mean(G_VP_losses)]\n","            # print(\"Epoch: %d, D_loss: %.2f [%.2f, %.2f, %.2f, %.2f], G_loss: %.2f [%.2f, %.2f, %.2f, %.2f]\" \\\n","            #       % (\n","            #           epoch, np.mean(D_losses), D_screen[0], D_screen[1], D_screen[2], D_screen[3], np.mean(G_losses),\n","            #           G_screen[0], G_screen[1], G_screen[2], G_screen[3]))\n","\n","            if epoch >= 1000 and epoch % self.args.eval_every == 0:\n","                self.eval(mode='test', epoch=epoch)\n","                # self.save_model()\n","\n","\n","\n","    def eval(self, mode='dev', epoch=0):\n","        self.Generator.eval()\n","        self.Discriminator.eval()\n","        # self.Extractor.eval()\n","        symbol2id = self.symbol2id\n","\n","        print('##EVALUATING ON %s DATA' % mode.upper())\n","        # test_candidates = json.load(open(self.args.data_path + \"/test_candidates_sub_10.json\"))\n","        test_candidates = json.load(open(self.args.data_path + \"/test_candidates.json\"))\n","\n","        hits10 = []\n","        hits5 = []\n","        hits1 = []\n","        mrr = []\n","\n","\n","        for query_ in sorted(test_candidates.keys()):\n","\n","\n","            hits10_ = []\n","            hits5_ = []\n","            hits1_ = []\n","            mrr_ = []\n","\n","            description = self.rela_matrix[self.rel2id[query_]]\n","            description = np.expand_dims(description, axis=0)\n","            descriptions = np.tile(description, (self.args.test_sample, 1))\n","            descriptions = Variable(torch.FloatTensor(descriptions)).cuda()\n","            relation_vecs = self.Generator(descriptions, self.test_noises)\n","            relation_vecs = relation_vecs.data.cpu().numpy()\n","\n","            for e1_rel, tail_candidates in test_candidates[query_].items():\n","                if self.args.dataset == \"NELL\":\n","                    head, rela, _ = e1_rel.split('\\t')\n","                elif self.args.dataset == \"Wiki\":\n","                    head, rela = e1_rel.split('\\t')\n","\n","                true = tail_candidates[0]\n","                query_pairs = []\n","                if head not in symbol2id or true not in symbol2id:\n","                    continue\n","                query_pairs.append([symbol2id[head], symbol2id[true]])\n","\n","\n","                query_left = []\n","                query_right = []\n","                query_left.append(self.ent2id[head])\n","                query_right.append(self.ent2id[true])\n","\n","                for tail in tail_candidates[1:]:\n","                    if tail not in symbol2id:\n","                        continue\n","                    query_pairs.append([symbol2id[head], symbol2id[tail]])\n","\n","                    query_left.append(self.ent2id[head])\n","                    query_right.append(self.ent2id[tail])\n","\n","                query = Variable(torch.LongTensor(query_pairs)).cuda()\n","\n","\n","                query_meta = self.get_meta(query_left, query_right)\n","                candidate_vecs, _ = self.Extractor(query, query, query_meta, query_meta)\n","\n","                candidate_vecs.detach()\n","                candidate_vecs = candidate_vecs.data.cpu().numpy()\n","\n","                # dot product\n","                # scores = candidate_vecs.dot(relation_vecs.transpose())\n","\n","                # cosine similarity\n","                scores = cosine_similarity(candidate_vecs, relation_vecs)\n","\n","                scores = scores.mean(axis=1)\n","\n","                assert scores.shape == (len(query_pairs),)\n","\n","                sort = list(np.argsort(scores))[::-1]\n","                rank = sort.index(0) + 1\n","                if rank <= 10:\n","                    hits10.append(1.0)\n","                    hits10_.append(1.0)\n","                else:\n","                    hits10.append(0.0)\n","                    hits10_.append(0.0)\n","                if rank <= 5:\n","                    hits5.append(1.0)\n","                    hits5_.append(1.0)\n","                else:\n","                    hits5.append(0.0)\n","                    hits5_.append(0.0)\n","                if rank <= 1:\n","                    hits1.append(1.0)\n","                    hits1_.append(1.0)\n","                else:\n","                    hits1.append(0.0)\n","                    hits1_.append(0.0)\n","                mrr.append(1.0 / rank)\n","                mrr_.append(1.0 / rank)\n","\n","\n","\n","        print('\\n############   ' + mode + ' ' + str(epoch) + '    #############')\n","        print('HITS10: {:.3f}, HITS5: {:.3f}, HITS1: {:.3f}, MAP: {:.3f}'.format(np.mean(hits10),\n","                                                                                 np.mean(hits5),\n","                                                                                 np.mean(hits1),\n","                                                                                 np.mean(mrr)))\n","        print('###################################')"],"metadata":{"id":"f8NMRDOG4VCm","executionInfo":{"status":"ok","timestamp":1666194175414,"user_tz":-480,"elapsed":893,"user":{"displayName":"黄雨峰","userId":"10355830370640481145"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["**8. Parameter Settings and Run Model**"],"metadata":{"id":"-WTdWxY6zam9"}},{"cell_type":"code","source":["if __name__ == '__main__':\n","\n","    parser = argparse.ArgumentParser()\n","    parser.add_argument(\"--data_dir\", default=\"/content/drive/MyDrive/ISWC_demo/ZS_KGC/data/\", type=str)\n","\n","    parser.add_argument(\"--dataset\", default=\"NELL\", type=str)\n","    parser.add_argument(\"--embed_model\", default='TransE', type=str)\n","\n","    # embedding dimension\n","    parser.add_argument(\"--embed_dim\", default=100, type=int, help='dimension of triple embedding')\n","    parser.add_argument(\"--ep_dim\", default=200, type=int, help='dimension of entity pair embedding')\n","    parser.add_argument(\"--fc1_dim\", default=250, type=int, help='dimension of hidden units in generator')\n","    parser.add_argument(\"--noise_dim\", default=15, type=int)\n","\n","    # feature extractor pretraining related\n","    parser.add_argument(\"--pretrain_batch_size\", default=64, type=int)\n","    parser.add_argument(\"--pretrain_few\", default=30, type=int)\n","    parser.add_argument(\"--pretrain_subepoch\", default=20, type=int)\n","    parser.add_argument(\"--pretrain_margin\", default=10.0, type=float, help='pretraining margin loss')\n","    parser.add_argument(\"--pretrain_times\", default=16000, type=int, help='total training steps for pretraining')\n","    parser.add_argument(\"--pretrain_loss_every\", default=500, type=int)\n","\n","    # adversarial training related\n","    # batch size\n","    parser.add_argument(\"--D_batch_size\", default=256, type=int)\n","    parser.add_argument(\"--G_batch_size\", default=256, type=int)\n","    parser.add_argument(\"--gan_batch_rela\", default=2, type=int)\n","    # learning rate\n","    parser.add_argument(\"--lr_G\", default=0.0001, type=float)\n","    parser.add_argument(\"--lr_D\", default=0.0001, type=float)\n","    parser.add_argument(\"--lr_E\", default=0.0005, type=float)\n","    # training times\n","    parser.add_argument(\"--train_times\", default=8000, type=int)\n","    parser.add_argument(\"--D_epoch\", default=5, type=int)\n","    parser.add_argument(\"--G_epoch\", default=1, type=int)\n","    # log\n","    parser.add_argument(\"--loss_every\", default=50, type=int)\n","    parser.add_argument(\"--eval_every\", default=200, type=int)\n","    # hyper-parameter\n","    parser.add_argument(\"--test_sample\", default=20, type=int, help='number of synthesized samples')\n","    parser.add_argument(\"--dropout\", default=0.5, type=float)\n","    parser.add_argument('--REG_W', default=0.001, type=float)\n","    parser.add_argument('--REG_Wz', default=0.0001, type=float)\n","    parser.add_argument(\"--max_neighbor\", default=50, type=int, help='neighbor number of each entity')\n","    parser.add_argument(\"--grad_clip\", default=5.0, type=float)\n","    parser.add_argument(\"--weight_decay\", default=0.0, type=float)\n","\n","    parser.add_argument(\"--fine_tune\", action='store_true')\n","    parser.add_argument(\"--aggregate\", default='max', type=str)\n","    parser.add_argument(\"--semantic_type\", default='rdfs', help='the type of relation embedding to input, options: {text, rdfs, rdfs_hie, rdfs_cons, rdfs_text}')\n","    # switch\n","    parser.add_argument(\"--pretrain_feature_extractor\", action='store_true')\n","    parser.add_argument(\"--load_trained_embed\", action='store_true', help='load well trained kg embeddings, such as TransE')\n","\n","\n","    parser.add_argument(\"--manual_seed\", type=int, default=6096)\n","    parser.add_argument('--gpu', type=int, default=0, help='device to use for iterate data, -1 means cpu [default: 0]')\n","\n","    args = parser.parse_known_args()[0]\n","\n","    args.data_path = os.path.join(args.data_dir, args.dataset)\n","\n","    args.save_path = os.path.join(args.data_path, 'expri_data', 'models_train')\n","\n","    if args.manual_seed is None:\n","        args.manual_seed = random.randint(1, 10000)\n","\n","    print(\"------HYPERPARAMETERS-------\")\n","    for k, v in vars(args).items():\n","        print(k + ': ' + str(v))\n","    print(\"----------------------------\")\n","\n","    np.random.seed(args.manual_seed)\n","    random.seed(args.manual_seed)\n","    torch.manual_seed(args.manual_seed)\n","    if torch.cuda.is_available():\n","        torch.cuda.set_device(args.gpu)\n","        print('using gpu {}'.format(args.gpu))\n","        torch.cuda.manual_seed_all(args.manual_seed)\n","        torch.backends.cudnn.deterministic = True\n","    else:\n","        print(\"GPU is not available!\")\n","\n","\n","\n","    trainer = Trainer(args)\n","    trainer.train()\n","    # trainer.test_()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IcOZS1iz4pya","outputId":"fff6c219-1e79-48fe-f567-3ed29b23134e"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["------HYPERPARAMETERS-------\n","data_dir: /content/drive/MyDrive/ISWC_demo/ZS_KGC/data/\n","dataset: NELL\n","embed_model: TransE\n","embed_dim: 100\n","ep_dim: 200\n","fc1_dim: 250\n","noise_dim: 15\n","pretrain_batch_size: 64\n","pretrain_few: 30\n","pretrain_subepoch: 20\n","pretrain_margin: 10.0\n","pretrain_times: 16000\n","pretrain_loss_every: 500\n","D_batch_size: 256\n","G_batch_size: 256\n","gan_batch_rela: 2\n","lr_G: 0.0001\n","lr_D: 0.0001\n","lr_E: 0.0005\n","train_times: 8000\n","D_epoch: 5\n","G_epoch: 1\n","loss_every: 50\n","eval_every: 200\n","test_sample: 20\n","dropout: 0.5\n","REG_W: 0.001\n","REG_Wz: 0.0001\n","max_neighbor: 50\n","grad_clip: 5.0\n","weight_decay: 0.0\n","fine_tune: False\n","aggregate: max\n","semantic_type: rdfs\n","pretrain_feature_extractor: False\n","load_trained_embed: False\n","manual_seed: 6096\n","gpu: 0\n","data_path: /content/drive/MyDrive/ISWC_demo/ZS_KGC/data/NELL\n","save_path: /content/drive/MyDrive/ISWC_demo/ZS_KGC/data/NELL/expri_data/models_train\n","----------------------------\n","using gpu 0\n","##LOADING CANDIDATES ENTITIES##\n","##LOADING SYMBOL ID AND SYMBOL EMBEDDING\n","num symbols: 65748\n","##DEFINE FEATURE EXTRACTOR\n","##DEFINE GENERATOR\n","##DEFINE DISCRIMINATOR\n","##BUILDING CONNECTION MATRIX\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["100%|██████████| 181053/181053 [00:00<00:00, 322462.45it/s]\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["\n","##START ADVERSARIAL TRAINING...\n","##LOADING TRAINING DATA\n","##LOADING CANDIDATES\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: 50, D_loss: 1.14 [-4.77, 0.06, 0.77, 8.95], G_loss: 42.98 [-0.71, 8.10, 0.05, 11.86]\n","Epoch: 100, D_loss: -4.12 [-7.90, 0.06, 2.49, 1.74], G_loss: 27.53 [-2.42, 1.60, 0.04, 9.45]\n","Epoch: 150, D_loss: -2.46 [-5.99, 0.06, 3.08, 0.44], G_loss: 19.94 [-3.04, 0.42, 0.08, 7.52]\n","Epoch: 200, D_loss: -1.73 [-2.36, 0.05, 0.40, 0.20], G_loss: 21.48 [-0.31, 0.25, 0.04, 7.18]\n","Epoch: 250, D_loss: -2.50 [1.80, 0.05, -4.61, 0.22], G_loss: 26.23 [4.68, 0.24, 0.05, 7.10]\n","Epoch: 300, D_loss: -3.28 [2.71, 0.05, -6.33, 0.15], G_loss: 27.29 [6.34, 0.17, 0.06, 6.93]\n","Epoch: 350, D_loss: -3.95 [2.92, 0.05, -7.26, 0.14], G_loss: 26.67 [7.27, 0.16, 0.04, 6.41]\n","Epoch: 400, D_loss: -4.16 [3.34, 0.05, -7.91, 0.12], G_loss: 28.39 [7.92, 0.17, 0.04, 6.77]\n","Epoch: 450, D_loss: -4.22 [3.72, 0.04, -8.35, 0.11], G_loss: 26.71 [8.41, 0.08, 0.03, 6.07]\n","Epoch: 500, D_loss: -4.31 [4.06, 0.04, -8.80, 0.11], G_loss: 27.04 [8.82, 0.09, 0.03, 6.04]\n","Epoch: 550, D_loss: -4.17 [4.61, 0.05, -9.23, 0.10], G_loss: 28.37 [9.28, 0.10, 0.06, 6.33]\n","Epoch: 600, D_loss: -4.02 [5.13, 0.05, -9.58, 0.09], G_loss: 28.04 [9.60, 0.11, 0.06, 6.11]\n","Epoch: 650, D_loss: -4.10 [5.43, 0.05, -9.95, 0.07], G_loss: 27.34 [9.96, 0.06, 0.05, 5.78]\n","Epoch: 700, D_loss: -4.08 [5.97, 0.05, -10.48, 0.06], G_loss: 27.10 [10.53, 0.04, 0.05, 5.51]\n","Epoch: 750, D_loss: -3.95 [6.33, 0.06, -10.68, 0.06], G_loss: 27.59 [10.76, 0.03, 0.05, 5.60]\n","Epoch: 800, D_loss: -3.85 [6.62, 0.05, -10.87, 0.05], G_loss: 27.78 [10.93, 0.07, 0.07, 5.59]\n","Epoch: 850, D_loss: -3.90 [6.90, 0.06, -11.20, 0.04], G_loss: 26.52 [11.19, 0.04, 0.06, 5.10]\n","Epoch: 900, D_loss: -3.80 [7.15, 0.06, -11.33, 0.04], G_loss: 27.04 [11.38, 0.04, 0.04, 5.21]\n","Epoch: 950, D_loss: -3.49 [7.64, 0.05, -11.47, 0.04], G_loss: 27.51 [11.52, 0.03, 0.05, 5.32]\n","Epoch: 1000, D_loss: -3.57 [7.90, 0.06, -11.82, 0.05], G_loss: 28.08 [11.92, 0.05, 0.07, 5.37]\n","##EVALUATING ON TEST DATA\n","\n","############   test 1000    #############\n","HITS10: 0.341, HITS5: 0.288, HITS1: 0.154, MAP: 0.221\n","###################################\n","Epoch: 1050, D_loss: -3.70 [8.08, 0.05, -12.11, 0.03], G_loss: 26.75 [12.26, 0.04, 0.06, 4.81]\n","Epoch: 1100, D_loss: -3.67 [8.33, 0.05, -12.34, 0.05], G_loss: 27.10 [12.30, 0.04, 0.07, 4.92]\n","Epoch: 1150, D_loss: -3.51 [8.74, 0.06, -12.58, 0.04], G_loss: 27.07 [12.58, 0.03, 0.04, 4.82]\n","Epoch: 1200, D_loss: -3.35 [9.13, 0.06, -12.78, 0.04], G_loss: 26.65 [12.84, 0.04, 0.06, 4.59]\n","##EVALUATING ON TEST DATA\n","\n","############   test 1200    #############\n","HITS10: 0.343, HITS5: 0.288, HITS1: 0.156, MAP: 0.223\n","###################################\n","Epoch: 1250, D_loss: -3.35 [9.51, 0.06, -13.17, 0.03], G_loss: 26.82 [13.22, 0.03, 0.06, 4.52]\n","Epoch: 1300, D_loss: -3.28 [9.68, 0.05, -13.25, 0.05], G_loss: 26.51 [13.38, 0.03, 0.06, 4.37]\n","Epoch: 1350, D_loss: -3.16 [9.87, 0.05, -13.31, 0.05], G_loss: 26.43 [13.39, 0.03, 0.07, 4.34]\n","Epoch: 1400, D_loss: -3.11 [10.23, 0.06, -13.60, 0.03], G_loss: 26.44 [13.52, 0.04, 0.06, 4.29]\n","##EVALUATING ON TEST DATA\n","\n","############   test 1400    #############\n","HITS10: 0.349, HITS5: 0.291, HITS1: 0.158, MAP: 0.226\n","###################################\n","Epoch: 1450, D_loss: -3.08 [10.55, 0.05, -13.89, 0.04], G_loss: 26.74 [13.89, 0.04, 0.06, 4.27]\n","Epoch: 1500, D_loss: -2.92 [10.72, 0.05, -13.88, 0.04], G_loss: 26.34 [14.04, 0.04, 0.05, 4.09]\n","Epoch: 1550, D_loss: -2.90 [10.97, 0.06, -14.11, 0.03], G_loss: 27.07 [14.13, 0.03, 0.06, 4.30]\n","Epoch: 1600, D_loss: -2.91 [11.09, 0.06, -14.22, 0.02], G_loss: 27.44 [14.22, 0.04, 0.05, 4.39]\n","##EVALUATING ON TEST DATA\n","\n","############   test 1600    #############\n","HITS10: 0.350, HITS5: 0.290, HITS1: 0.158, MAP: 0.226\n","###################################\n","Epoch: 1650, D_loss: -2.74 [11.14, 0.06, -14.08, 0.03], G_loss: 26.58 [14.23, 0.03, 0.05, 4.11]\n","Epoch: 1700, D_loss: -2.69 [11.46, 0.06, -14.34, 0.02], G_loss: 26.50 [14.41, 0.02, 0.06, 4.02]\n","Epoch: 1750, D_loss: -2.61 [11.66, 0.06, -14.46, 0.03], G_loss: 25.32 [14.48, 0.01, 0.07, 3.61]\n","Epoch: 1800, D_loss: -2.67 [11.72, 0.06, -14.59, 0.03], G_loss: 26.18 [14.68, 0.02, 0.05, 3.83]\n","##EVALUATING ON TEST DATA\n","\n","############   test 1800    #############\n","HITS10: 0.348, HITS5: 0.289, HITS1: 0.157, MAP: 0.225\n","###################################\n","Epoch: 1850, D_loss: -2.59 [11.98, 0.07, -14.76, 0.01], G_loss: 26.30 [14.84, 0.02, 0.07, 3.81]\n","Epoch: 1900, D_loss: -2.49 [12.33, 0.07, -15.00, 0.01], G_loss: 26.82 [15.03, 0.02, 0.06, 3.92]\n","Epoch: 1950, D_loss: -2.46 [12.46, 0.06, -15.09, 0.01], G_loss: 24.96 [15.12, 0.01, 0.09, 3.28]\n","Epoch: 2000, D_loss: -2.37 [12.50, 0.06, -15.05, 0.02], G_loss: 25.71 [15.04, 0.01, 0.06, 3.55]\n","##EVALUATING ON TEST DATA\n","\n","############   test 2000    #############\n","HITS10: 0.350, HITS5: 0.289, HITS1: 0.157, MAP: 0.225\n","###################################\n","Epoch: 2050, D_loss: -2.29 [12.70, 0.06, -15.16, 0.01], G_loss: 25.54 [15.22, 0.01, 0.06, 3.44]\n","Epoch: 2100, D_loss: -2.28 [12.85, 0.06, -15.29, 0.01], G_loss: 25.85 [15.31, 0.02, 0.04, 3.51]\n","Epoch: 2150, D_loss: -2.17 [12.74, 0.06, -15.06, 0.01], G_loss: 25.95 [15.01, 0.02, 0.06, 3.64]\n","Epoch: 2200, D_loss: -2.15 [12.97, 0.07, -15.28, 0.01], G_loss: 25.28 [15.36, 0.01, 0.06, 3.30]\n","##EVALUATING ON TEST DATA\n","\n","############   test 2200    #############\n","HITS10: 0.349, HITS5: 0.286, HITS1: 0.156, MAP: 0.224\n","###################################\n","Epoch: 2250, D_loss: -2.13 [13.16, 0.06, -15.44, 0.01], G_loss: 25.54 [15.48, 0.02, 0.07, 3.35]\n","Epoch: 2300, D_loss: -2.16 [13.48, 0.07, -15.80, 0.01], G_loss: 25.10 [15.80, 0.01, 0.06, 3.10]\n","Epoch: 2350, D_loss: -2.06 [13.59, 0.06, -15.80, 0.01], G_loss: 24.80 [15.82, 0.01, 0.07, 2.99]\n","Epoch: 2400, D_loss: -2.07 [13.47, 0.06, -15.68, 0.01], G_loss: 25.53 [15.77, 0.01, 0.05, 3.25]\n","##EVALUATING ON TEST DATA\n","\n","############   test 2400    #############\n","HITS10: 0.346, HITS5: 0.288, HITS1: 0.158, MAP: 0.224\n","###################################\n","Epoch: 2450, D_loss: -2.02 [13.76, 0.06, -15.92, 0.01], G_loss: 24.27 [15.95, 0.01, 0.06, 2.77]\n","Epoch: 2500, D_loss: -1.95 [14.02, 0.06, -16.10, 0.01], G_loss: 24.70 [16.07, 0.01, 0.06, 2.87]\n","Epoch: 2550, D_loss: -1.95 [14.00, 0.06, -16.10, 0.01], G_loss: 24.26 [16.19, 0.01, 0.08, 2.69]\n","Epoch: 2600, D_loss: -1.91 [13.95, 0.06, -15.99, 0.01], G_loss: 24.37 [16.12, 0.01, 0.05, 2.75]\n","##EVALUATING ON TEST DATA\n","\n","############   test 2600    #############\n","HITS10: 0.342, HITS5: 0.285, HITS1: 0.155, MAP: 0.222\n","###################################\n","Epoch: 2650, D_loss: -1.92 [14.09, 0.06, -16.14, 0.00], G_loss: 24.18 [16.01, 0.00, 0.05, 2.72]\n","Epoch: 2700, D_loss: -1.85 [14.29, 0.07, -16.27, 0.01], G_loss: 24.46 [16.38, 0.01, 0.06, 2.69]\n","Epoch: 2750, D_loss: -1.87 [14.18, 0.07, -16.19, 0.01], G_loss: 24.23 [16.16, 0.01, 0.06, 2.69]\n","Epoch: 2800, D_loss: -1.87 [14.27, 0.07, -16.27, 0.01], G_loss: 24.00 [16.30, 0.01, 0.08, 2.56]\n","##EVALUATING ON TEST DATA\n","\n","############   test 2800    #############\n","HITS10: 0.342, HITS5: 0.284, HITS1: 0.154, MAP: 0.220\n","###################################\n","Epoch: 2850, D_loss: -1.79 [14.55, 0.06, -16.47, 0.01], G_loss: 24.19 [16.49, 0.01, 0.06, 2.57]\n","Epoch: 2900, D_loss: -1.79 [14.91, 0.06, -16.83, 0.01], G_loss: 24.29 [16.82, 0.01, 0.06, 2.49]\n","Epoch: 2950, D_loss: -1.79 [14.66, 0.06, -16.58, 0.01], G_loss: 24.60 [16.68, 0.02, 0.07, 2.63]\n","Epoch: 3000, D_loss: -1.77 [14.63, 0.08, -16.52, 0.01], G_loss: 24.12 [16.61, 0.00, 0.08, 2.50]\n","##EVALUATING ON TEST DATA\n","\n","############   test 3000    #############\n","HITS10: 0.342, HITS5: 0.282, HITS1: 0.151, MAP: 0.218\n","###################################\n","Epoch: 3050, D_loss: -1.84 [14.86, 0.06, -16.82, 0.01], G_loss: 24.15 [16.86, 0.01, 0.07, 2.43]\n","Epoch: 3100, D_loss: -1.80 [15.06, 0.07, -16.98, 0.00], G_loss: 24.05 [17.03, 0.00, 0.08, 2.34]\n","Epoch: 3150, D_loss: -1.77 [15.30, 0.06, -17.19, 0.01], G_loss: 24.55 [17.15, 0.00, 0.07, 2.47]\n","Epoch: 3200, D_loss: -1.67 [15.39, 0.06, -17.18, 0.01], G_loss: 24.05 [17.34, 0.00, 0.06, 2.24]\n","##EVALUATING ON TEST DATA\n","\n","############   test 3200    #############\n","HITS10: 0.342, HITS5: 0.282, HITS1: 0.153, MAP: 0.219\n","###################################\n","Epoch: 3250, D_loss: -1.63 [15.60, 0.06, -17.34, 0.00], G_loss: 24.10 [17.30, 0.00, 0.07, 2.27]\n","Epoch: 3300, D_loss: -1.68 [15.58, 0.06, -17.37, 0.01], G_loss: 23.95 [17.51, 0.01, 0.06, 2.14]\n","Epoch: 3350, D_loss: -1.69 [15.56, 0.05, -17.36, 0.01], G_loss: 24.14 [17.24, 0.01, 0.07, 2.30]\n","Epoch: 3400, D_loss: -1.71 [15.62, 0.05, -17.44, 0.00], G_loss: 24.31 [17.40, 0.01, 0.06, 2.30]\n","##EVALUATING ON TEST DATA\n","\n","############   test 3400    #############\n","HITS10: 0.339, HITS5: 0.281, HITS1: 0.154, MAP: 0.219\n","###################################\n","Epoch: 3450, D_loss: -1.72 [15.72, 0.06, -17.55, 0.00], G_loss: 24.00 [17.60, 0.00, 0.06, 2.13]\n","Epoch: 3500, D_loss: -1.63 [15.81, 0.07, -17.55, 0.01], G_loss: 24.01 [17.69, 0.00, 0.05, 2.11]\n","Epoch: 3550, D_loss: -1.56 [15.83, 0.06, -17.50, 0.01], G_loss: 24.06 [17.59, 0.01, 0.07, 2.15]\n","Epoch: 3600, D_loss: -1.62 [15.95, 0.05, -17.67, 0.00], G_loss: 23.54 [17.61, 0.00, 0.07, 1.98]\n","##EVALUATING ON TEST DATA\n"]}]},{"cell_type":"markdown","source":["**Parameters in other Settings**\n","\n","\n","---\n","\n","*   **run OntoZSL on NELL with \"RDFS+literal\"**\n","\n","------HYPERPARAMETERS-------\n","data_dir: /content/drive/MyDrive/ISWC_demo/ZS_KGC/data;\n","dataset: NELL;\n","embed_model: TransE;\n","embed_dim: 100;\n","ep_dim: 200;\n","fc1_dim: 250;\n","noise_dim: 15;\n","pretrain_batch_size: 64;\n","pretrain_few: 30;\n","pretrain_subepoch: 20;\n","pretrain_margin: 10.0;\n","pretrain_times: 16000;\n","pretrain_loss_every: 500;\n","D_batch_size: 256;\n","G_batch_size: 256;\n","gan_batch_rela: 2;\n","lr_G: 0.0001;\n","lr_D: 0.0001;\n","lr_E: 0.0005;\n","train_times: 8000;\n","D_epoch: 5;\n","G_epoch: 1;\n","loss_every: 50;\n","eval_every: 200;\n","test_sample: 20;\n","dropout: 0.5;\n","REG_W: 0.001;\n","REG_Wz: 0.0001;\n","max_neighbor: 50;\n","grad_clip: 5.0;\n","weight_decay: 0.0;\n","fine_tune: False;\n","aggregate: max;\n","semantic_type: rdfs_text;\n","pretrain_feature_extractor: False;\n","load_trained_embed: False;\n","manual_seed: 6096;\n","\n","\n","*   **run OntoZSL on Wiki with \"RDFS\"**\n","\n","------HYPERPARAMETERS-------\n","data_dir: /content/drive/MyDrive/ISWC_demo/ZS_KGC/data;\n","dataset: Wiki;\n","embed_model: TransE;\n","embed_dim: 50;\n","ep_dim: 100;\n","fc1_dim: 200;\n","noise_dim: 15;\n","pretrain_batch_size: 64;\n","pretrain_few: 30;\n","pretrain_subepoch: 20;\n","pretrain_margin: 10.0;\n","pretrain_times: 16000;\n","pretrain_loss_every: 500;\n","D_batch_size: 64;\n","G_batch_size: 64;\n","gan_batch_rela: 8;\n","lr_G: 0.0001;\n","lr_D: 0.0001;\n","lr_E: 0.0005;\n","train_times: 8000;\n","D_epoch: 5;\n","G_epoch: 1;\n","loss_every: 50;\n","eval_every: 200;\n","test_sample: 20;\n","dropout: 0.5;\n","REG_W: 0.001;\n","REG_Wz: 0.0001;\n","max_neighbor: 50;\n","grad_clip: 5.0;\n","weight_decay: 0.0;\n","fine_tune: False;\n","aggregate: max;\n","semantic_type: rdfs;\n","pretrain_feature_extractor: False;\n","load_trained_embed: False;\n","manual_seed: 6096;\n","gpu: 1;\n","\n","\n","*   **run OntoZSL on Wiki with \"RDFS+literal\"**\n","\n","------HYPERPARAMETERS-------\n","data_dir: /content/drive/MyDrive/ISWC_demo/ZS_KGC/data;\n","dataset: Wiki;\n","embed_model: TransE;\n","embed_dim: 50;\n","ep_dim: 100;\n","fc1_dim: 200;\n","noise_dim: 15;\n","pretrain_batch_size: 64;\n","pretrain_few: 30;\n","pretrain_subepoch: 20;\n","pretrain_margin: 10.0;\n","pretrain_times: 16000;\n","pretrain_loss_every: 500;\n","D_batch_size: 64;\n","G_batch_size: 64;\n","gan_batch_rela: 8;\n","lr_G: 0.0001;\n","lr_D: 0.0001;\n","lr_E: 0.0005;\n","train_times: 8000;\n","D_epoch: 5;\n","G_epoch: 1;\n","loss_every: 50;\n","eval_every: 200;\n","test_sample: 20;\n","dropout: 0.5;\n","REG_W: 0.001;\n","REG_Wz: 0.0001;\n","max_neighbor: 50;\n","grad_clip: 5.0;\n","weight_decay: 0.0;\n","fine_tune: False;\n","aggregate: max;\n","semantic_type: rdfs_text;\n","pretrain_feature_extractor: False;\n","load_trained_embed: False;\n","manual_seed: 6096;\n"],"metadata":{"id":"pbtlPnx5zhsa"}}]}